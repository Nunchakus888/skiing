#!/usr/bin/env python3
"""
ç²¾ç¡®å»é™¤æ°´å° - ä¿æŠ¤åŸå›¾ç‰ˆæœ¬
ç­–ç•¥ï¼š
1. ä½¿ç”¨ OCR ç²¾ç¡®è¯†åˆ«æ°´å°æ–‡å­—ä½ç½®
2. åªä¿®å¤æ°´å°åŒºåŸŸï¼Œå®Œå…¨ä¸æ”¹å˜å…¶ä»–éƒ¨åˆ†
3. ä½¿ç”¨ä¿å®ˆçš„ SD å‚æ•°ï¼Œä¿æŠ¤äººç‰©å’ŒèƒŒæ™¯
"""

import cv2
import numpy as np
from PIL import Image
import torch
from diffusers import StableDiffusionInpaintPipeline
import os

class PreciseWatermarkRemover:
    """ç²¾ç¡®æ°´å°å»é™¤å™¨ - åªå¤„ç†æ–‡å­—ï¼Œä¿æŠ¤åŸå›¾"""
    
    def __init__(self, device=None):
        """åˆå§‹åŒ–æ¨¡å‹"""
        if device is None:
            if torch.cuda.is_available():
                device = "cuda"
                dtype = torch.float16
            elif torch.backends.mps.is_available():
                device = "mps"
                dtype = torch.float32
            else:
                device = "cpu"
                dtype = torch.float32
        
        print(f"ğŸš€ åˆå§‹åŒ– SD Inpainting æ¨¡å‹ï¼ˆè®¾å¤‡: {device}ï¼‰...")
        
        self.device = device
        self.dtype = dtype
        
        # åŠ è½½æ¨¡å‹
        self.pipe = StableDiffusionInpaintPipeline.from_pretrained(
            "runwayml/stable-diffusion-inpainting",
            torch_dtype=dtype,
            safety_checker=None,
        )
        self.pipe = self.pipe.to(device)
        
        if device == "cuda":
            self.pipe.enable_attention_slicing()
        
        print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ\n")
    
    def detect_text_with_ocr(self, image_path):
        """
        ä½¿ç”¨ OCR ç²¾ç¡®è¯†åˆ«æ°´å°æ–‡å­—ä½ç½®
        è¿”å›ç²¾ç¡®çš„æ–‡å­— mask
        """
        try:
            import easyocr
        except ImportError:
            print("âŒ éœ€è¦å®‰è£… EasyOCR")
            print("   uv pip install easyocr")
            return None
        
        print("ğŸ“ ä½¿ç”¨ OCR è¯†åˆ«æ°´å°æ–‡å­—...")
        
        img = cv2.imread(image_path)
        if img is None:
            return None
        
        h, w = img.shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # åˆå§‹åŒ– OCR
        reader = easyocr.Reader(['ch_sim', 'en'], gpu=False, verbose=False)
        results = reader.readtext(image_path)
        
        # æ°´å°å…³é”®è¯
        watermark_keywords = [
            'æ»‘å‘—', 'app', '1000', 'ä¸‡', 'é›ªå‹', 'é€‰æ‹©',
            'é…’åº—', 'æ•™ç»ƒ', 'æ‘„å½±å¸ˆ', 'çº¦ç©', 'é›ªç¥¨', 'BDH'
        ]
        
        # æ ¸å¿ƒäººç‰©ä¿æŠ¤åŒºåŸŸï¼ˆåªä¿æŠ¤è„¸éƒ¨æ ¸å¿ƒ - ç¼©å°åˆ° 20% x 20%ï¼‰
        center_x, center_y = w // 2, h // 2
        face_w, face_h = int(w * 0.10), int(h * 0.10)  # æ ¸å¿ƒè„¸éƒ¨åŒºåŸŸ
        face_x1 = center_x - face_w
        face_x2 = center_x + face_w
        face_y1 = center_y - face_h
        face_y2 = center_y + face_h
        
        detected_count = 0
        person_area_count = 0  # äººç‰©åŒºåŸŸçš„æ°´å°ï¼ˆéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
        
        for (bbox, text, prob) in results:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ°´å°
            is_watermark = any(keyword in text for keyword in watermark_keywords)
            
            if not is_watermark or prob < 0.2:
                continue
            
            # è·å–è¾¹ç•Œæ¡†
            pts = np.array(bbox, dtype=np.int32)
            center_x_text = int(np.mean(pts[:, 0]))
            center_y_text = int(np.mean(pts[:, 1]))
            
            # æ£€æŸ¥æ˜¯å¦åœ¨æ ¸å¿ƒè„¸éƒ¨åŒºåŸŸï¼ˆçœŸæ­£éœ€è¦ä¿æŠ¤çš„ï¼‰
            in_face_area = (face_x1 <= center_x_text <= face_x2 and 
                           face_y1 <= center_y_text <= face_y2)
            
            if in_face_area:
                print(f"   ğŸ›¡ï¸  è·³è¿‡æ ¸å¿ƒè„¸éƒ¨: '{text}'")
                continue
            
            # ç²¾ç¡®æ ‡è®°æ–‡å­—åŒºåŸŸï¼ˆé€‚åº¦æ‰©å¤§ï¼‰
            width = int(np.max(pts[:, 0]) - np.min(pts[:, 0]))
            height = int(np.max(pts[:, 1]) - np.min(pts[:, 1]))
            
            # æ£€æŸ¥æ˜¯å¦åœ¨äººç‰©åŒºåŸŸï¼ˆèº«ä½“éƒ¨åˆ†ï¼‰
            person_x1 = center_x - int(w * 0.25)
            person_x2 = center_x + int(w * 0.25)
            person_y1 = center_y - int(h * 0.35)
            person_y2 = center_y + int(h * 0.35)
            
            in_person_area = (person_x1 <= center_x_text <= person_x2 and 
                             person_y1 <= center_y_text <= person_y2)
            
            # æ ¹æ®ä½ç½®è°ƒæ•´æ‰©å±•æ¯”ä¾‹
            if in_person_area:
                # äººç‰©åŒºåŸŸï¼šä¿å®ˆæ‰©å±•ï¼Œé¿å…ç ´åè¡£æœçº¹ç†
                expand_ratio = 1.2
                person_area_count += 1
                location_tag = "ğŸ‘¤äººç‰©"
            else:
                # èƒŒæ™¯åŒºåŸŸï¼šæ­£å¸¸æ‰©å±•
                expand_ratio = 1.3
                location_tag = "ğŸŒ„èƒŒæ™¯"
            
            new_width = int(width * expand_ratio)
            new_height = int(height * expand_ratio)
            
            x1 = max(0, center_x_text - new_width // 2)
            y1 = max(0, center_y_text - new_height // 2)
            x2 = min(w, center_x_text + new_width // 2)
            y2 = min(h, center_y_text + new_height // 2)
            
            # æ ‡è®°åŒºåŸŸ
            cv2.rectangle(mask, (x1, y1), (x2, y2), 255, -1)
            detected_count += 1
            print(f"   âœ“ {location_tag} æ°´å°: '{text}' (ä½ç½®: {center_x_text}, {center_y_text})")
        
        # æ¸©å’Œçš„è†¨èƒ€ï¼ˆè¿æ¥ç›¸é‚»æ–‡å­—ï¼‰
        if detected_count > 0:
            kernel = np.ones((8, 8), np.uint8)
            mask = cv2.dilate(mask, kernel, iterations=1)
        
        print(f"\n   æ£€æµ‹ç»“æœ: æ€»å…± {detected_count} å¤„æ°´å°")
        print(f"   - äººç‰©åŒºåŸŸ: {person_area_count} å¤„ï¼ˆä¿å®ˆå¤„ç†ï¼‰")
        print(f"   - èƒŒæ™¯åŒºåŸŸ: {detected_count - person_area_count} å¤„")
        
        # ç»Ÿè®¡
        watermark_pixels = np.sum(mask > 0)
        percentage = (watermark_pixels / (h * w)) * 100
        print(f"   æ°´å°åŒºåŸŸ: {watermark_pixels:,} åƒç´  ({percentage:.1f}%)\n")
        
        return mask
    
    def remove_watermark(self, image_path, mask=None, output_path=None,
                        num_inference_steps=50, strength=0.95):
        """
        ç²¾ç¡®å»é™¤æ°´å°
        
        Args:
            strength: ä¿®å¤å¼ºåº¦ (0.8-1.0)
                     0.8-0.9: ä¿å®ˆï¼Œæ›´å¥½åœ°ä¿æŒåŸå›¾
                     0.95-1.0: æ¿€è¿›ï¼Œå®Œå…¨é‡ç»˜
        """
        # è¯»å–å›¾ç‰‡
        image = Image.open(image_path).convert("RGB")
        original_size = image.size
        
        # è‡ªåŠ¨æ£€æµ‹æ°´å°
        if mask is None:
            mask = self.detect_text_with_ocr(image_path)
            if mask is None:
                print("âŒ OCR æ£€æµ‹å¤±è´¥")
                return None, None
        
        # è½¬æ¢ mask
        if isinstance(mask, np.ndarray):
            mask_pil = Image.fromarray(mask).convert("L")
        else:
            mask_pil = mask
        
        mask_pil = mask_pil.resize(original_size, Image.LANCZOS)
        
        # è°ƒæ•´å°ºå¯¸ï¼ˆ8 çš„å€æ•°ï¼‰
        def resize_to_multiple_of_8(img):
            w, h = img.size
            new_w = (w // 8) * 8
            new_h = (h // 8) * 8
            return img.resize((new_w, new_h), Image.LANCZOS)
        
        image_resized = resize_to_multiple_of_8(image)
        mask_resized = resize_to_multiple_of_8(mask_pil)
        
        print(f"ğŸ¨ å¼€å§‹ AI ä¿®å¤...")
        print(f"   åŸå§‹å°ºå¯¸: {original_size}")
        print(f"   å¤„ç†å°ºå¯¸: {image_resized.size}")
        print(f"   æ¨ç†æ­¥æ•°: {num_inference_steps}")
        print(f"   ä¿®å¤å¼ºåº¦: {strength} (ä¿æŠ¤åŸå›¾)")
        
        # ä¼˜åŒ–çš„æç¤ºè¯ï¼ˆä¸“é—¨é’ˆå¯¹æ»‘é›ªç…§ç‰‡ï¼‰
        prompt = """professional skiing photo, natural snow mountain landscape, 
                    clear blue sky, natural lighting, high quality, photorealistic, 
                    clean image without any text or watermark"""
        
        negative_prompt = """text, watermark, logo, words, letters, numbers, 
                            chinese characters, overlay text, blurry, low quality, 
                            distorted, artificial, fake"""
        
        # SD Inpainting
        result = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=image_resized,
            mask_image=mask_resized,
            num_inference_steps=num_inference_steps,
            guidance_scale=7.5,
            strength=strength,  # ä¿å®ˆçš„å¼ºåº¦
        ).images[0]
        
        # æ¢å¤åŸå§‹å°ºå¯¸
        if result.size != original_size:
            result = result.resize(original_size, Image.LANCZOS)
        
        # å¯é€‰ï¼šæ··åˆåŸå›¾å’Œä¿®å¤ç»“æœï¼ˆè¿›ä¸€æ­¥ä¿æŠ¤åŸå›¾ï¼‰
        result_array = np.array(result)
        original_array = np.array(image)
        mask_array = np.array(mask_pil)
        
        # åªåœ¨ mask åŒºåŸŸåº”ç”¨ä¿®å¤ï¼Œå…¶ä»–åœ°æ–¹ä¿æŒåŸæ ·
        mask_3d = np.stack([mask_array] * 3, axis=2) / 255.0
        blended = (result_array * mask_3d + original_array * (1 - mask_3d)).astype(np.uint8)
        result_blended = Image.fromarray(blended)
        
        # ä¿å­˜ç»“æœ
        if output_path is None:
            base, ext = os.path.splitext(image_path)
            output_path = f"{base}_precise{ext}"
        
        result_blended.save(output_path, quality=95)
        print(f"âœ“ ä¿®å¤å®Œæˆï¼ä¿å­˜åˆ°: {output_path}\n")
        
        return result_blended, output_path


def main():
    """å¿«é€Ÿæµ‹è¯•"""
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: uv run python remove_watermark_precise.py <å›¾ç‰‡è·¯å¾„> [æ¨ç†æ­¥æ•°]")
        print("\nç¤ºä¾‹:")
        print("  å¿«é€Ÿæ¨¡å¼: uv run python remove_watermark_precise.py images/11-22/02.JPG")
        print("  é«˜è´¨é‡:   uv run python remove_watermark_precise.py images/11-22/02.JPG 70")
        print("  æè‡´è´¨é‡: uv run python remove_watermark_precise.py images/11-22/02.JPG 100")
        print("\næ¨èæ­¥æ•°:")
        print("  30-40: å¿«é€Ÿï¼ˆ1-2åˆ†é’Ÿï¼‰")
        print("  50-70: æ ‡å‡†è´¨é‡ï¼ˆ2-3åˆ†é’Ÿï¼‰â­æ¨è")
        print("  80-100: æœ€é«˜è´¨é‡ï¼ˆ3-5åˆ†é’Ÿï¼‰")
        return
    
    image_path = sys.argv[1]
    
    # è·å–æ¨ç†æ­¥æ•°ï¼ˆé»˜è®¤70ï¼‰
    num_steps = int(sys.argv[2]) if len(sys.argv) > 2 else 70
    
    if not os.path.exists(image_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    # æ ¹æ®æ­¥æ•°é€‰æ‹©æ¨¡å¼
    if num_steps >= 80:
        mode = "ğŸŒŸ æè‡´è´¨é‡æ¨¡å¼"
    elif num_steps >= 60:
        mode = "â­ é«˜è´¨é‡æ¨¡å¼"
    elif num_steps >= 40:
        mode = "âœ“ æ ‡å‡†æ¨¡å¼"
    else:
        mode = "âš¡ å¿«é€Ÿæ¨¡å¼"
    
    print("=" * 70)
    print("ğŸ¯ ç²¾ç¡®æ°´å°å»é™¤å·¥å…·")
    print(f"   æ¨¡å¼: {mode} ({num_steps} æ­¥)")
    print("   ç­–ç•¥: åªå»é™¤æ–‡å­—ï¼Œå®Œå…¨ä¿æŠ¤åŸå›¾")
    print("=" * 70)
    print()
    
    # åˆå§‹åŒ–
    remover = PreciseWatermarkRemover()
    
    # å¤„ç†
    remover.remove_watermark(
        image_path,
        num_inference_steps=num_steps,
        strength=0.95  # ä¿å®ˆçš„ä¿®å¤å¼ºåº¦
    )
    
    print("=" * 70)
    print("âœ“ å®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    main()

