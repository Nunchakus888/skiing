#!/usr/bin/env python3
"""
ä½¿ç”¨ AI æ¨¡å‹å»é™¤æ°´å° - æ™ºèƒ½ä¿®å¤æ–¹æ¡ˆ
æ”¯æŒå¤šç§ä¿®å¤åç«¯ï¼š
1. LaMa (æ¨è) - æœ€å…ˆè¿›çš„å›¾åƒä¿®å¤æ¨¡å‹
2. cv2.inpaint - ä¼ ç»Ÿå¿«é€Ÿä¿®å¤

åŸºäºå›¾åƒç‰¹å¾æ£€æµ‹æ°´å°åŒºåŸŸï¼Œä½¿ç”¨AIæ¨¡å‹æ™ºèƒ½ä¿®å¤
"""

import cv2
import numpy as np
from PIL import Image
import os
import re

# AIä¿®å¤æ¨¡å‹æ ‡å¿—
LAMA_AVAILABLE = False
try:
    from lama_cleaner.model_manager import ModelManager
    from lama_cleaner.schema import Config, HDStrategy, LDMSampler
    LAMA_AVAILABLE = True
    print("âœ“ LaMa AI ä¿®å¤æ¨¡å‹å·²åŠ è½½")
except ImportError:
    print("âš ï¸  LaMa æ¨¡å‹æœªå®‰è£…ï¼Œä½¿ç”¨ä¼ ç»Ÿ cv2.inpaint")
    print("   å®‰è£…æ–¹æ³•: uv pip install lama-cleaner")

def detect_watermark_mask(image_path):
    """
    ç²¾ç¡®æ£€æµ‹å›¾ç‰‡ä¸­çš„æ°´å°ä½ç½®ï¼ˆæ”¹è¿›ç‰ˆï¼‰
    åªæ ‡è®°æ˜æ˜¾çš„æ°´å°åŒºåŸŸï¼Œé¿å…è¯¯ä¼¤äººç‰©å’ŒèƒŒæ™¯
    è¿”å›æ°´å°çš„ maskï¼ˆç™½è‰²=æ°´å°åŒºåŸŸï¼‰
    """
    # è¯»å–å›¾ç‰‡
    img = cv2.imread(image_path)
    
    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦è¯»å–æˆåŠŸ
    if img is None:
        print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶: {image_path}")
        return None, None
    
    # è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # åˆ›å»ºç©ºç™½ mask
    mask = np.zeros(gray.shape, dtype=np.uint8)
    
    # æ–¹æ³•1: æ£€æµ‹éå¸¸æµ…çš„æ–‡å­—ï¼ˆæ°´å°é€šå¸¸æ˜¯åŠé€æ˜çš„æµ…è‰²ï¼‰
    # åªæ£€æµ‹éå¸¸äº®çš„åŒºåŸŸ (é˜ˆå€¼æé«˜åˆ° 240ï¼Œæ›´ä¿å®ˆ)
    _, light_mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)
    
    # æ–¹æ³•2: ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼æ£€æµ‹å±€éƒ¨å¼‚å¸¸ï¼ˆæ–‡å­—è¾¹ç¼˜ï¼‰
    # ä½†åªä¿ç•™å°å—åŒºåŸŸï¼ˆæ–‡å­—ç‰¹å¾ï¼‰
    adaptive = cv2.adaptiveThreshold(
        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 15, 2
    )
    
    # åè½¬ï¼ˆè®©æ–‡å­—å˜ç™½ï¼‰
    adaptive_inv = cv2.bitwise_not(adaptive)
    
    # åªä¿ç•™å°çš„è¿é€šåŒºåŸŸï¼ˆå¯èƒ½æ˜¯æ–‡å­—ï¼‰
    # ä½¿ç”¨å½¢æ€å­¦æ“ä½œå»é™¤å¤§çš„åŒºåŸŸï¼ˆå¯èƒ½æ˜¯äººç‰©ã€èƒŒæ™¯ï¼‰
    kernel_small = np.ones((2, 2), np.uint8)
    adaptive_filtered = cv2.morphologyEx(adaptive_inv, cv2.MORPH_OPEN, kernel_small)
    
    # å†ä½¿ç”¨é—­è¿ç®—è¿æ¥æ–‡å­—ç¬”ç”»
    kernel_close = np.ones((3, 15), np.uint8)  # æ¨ªå‘è¿æ¥ï¼ˆä¸­æ–‡å­—ç¬¦ç‰¹å¾ï¼‰
    adaptive_filtered = cv2.morphologyEx(adaptive_filtered, cv2.MORPH_CLOSE, kernel_close)
    
    # ç»“åˆä¸¤ç§æ–¹æ³•ï¼šåªä¿ç•™æ—¢æµ…è‰²åˆæœ‰æ–‡å­—ç‰¹å¾çš„åŒºåŸŸ
    mask = cv2.bitwise_and(light_mask, adaptive_filtered)
    
    # è¿‡æ»¤æ‰å¤ªå°çš„åŒºåŸŸï¼ˆå™ªç‚¹ï¼‰å’Œå¤ªå¤§çš„åŒºåŸŸï¼ˆäººç‰©ï¼‰
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    final_mask = np.zeros(gray.shape, dtype=np.uint8)
    for contour in contours:
        area = cv2.contourArea(contour)
        # åªä¿ç•™åˆç†å¤§å°çš„åŒºåŸŸï¼ˆæ–‡å­—é€šå¸¸æ˜¯è¿™ä¸ªèŒƒå›´ï¼‰
        if 50 < area < 5000:
            cv2.drawContours(final_mask, [contour], -1, 255, -1)
    
    # è½»å¾®è†¨èƒ€ï¼Œç¡®ä¿è¦†ç›–æ–‡å­—è¾¹ç¼˜
    kernel = np.ones((3, 3), np.uint8)
    final_mask = cv2.dilate(final_mask, kernel, iterations=1)
    
    return img, final_mask

def detect_person_region(img, conservative=True):
    """
    æ£€æµ‹å›¾ç‰‡ä¸­çš„äººç‰©åŒºåŸŸï¼Œç”¨äºæ’é™¤äººç‰©é¿å…è¯¯ä¼¤
    è¿”å›äººç‰©åŒºåŸŸçš„ mask
    
    ç­–ç•¥ï¼šä¿å®ˆä¼°è®¡ï¼Œå®å¯å¤šæ’é™¤ä¹Ÿä¸è¦è¯¯ä¼¤äººç‰©
    
    Args:
        conservative: æ˜¯å¦ä½¿ç”¨ä¿å®ˆç­–ç•¥ï¼ˆæ›´å¤§çš„ä¿æŠ¤åŒºåŸŸï¼‰
    """
    h, w = img.shape[:2]
    person_mask = np.zeros((h, w), dtype=np.uint8)
    
    center_x, center_y = w // 2, h // 2
    
    if conservative:
        # ä¿å®ˆç­–ç•¥ï¼šç”¨äºé¢œè‰²æ£€æµ‹ç­‰å¯èƒ½è¯¯ä¼¤çš„åœºæ™¯
        width_range = int(w * 0.45)  # å·¦å³å„45%
        height_range = int(h * 0.55)  # ä¸Šä¸‹å„55%
    else:
        # ç²¾ç¡®ç­–ç•¥ï¼šç”¨äºæ¨¡å¼åŒ¹é…ç­‰ç²¾ç¡®åº¦é«˜çš„åœºæ™¯
        width_range = int(w * 0.30)  # å·¦å³å„30%
        height_range = int(h * 0.40)  # ä¸Šä¸‹å„40%
    
    x1 = max(0, center_x - width_range)
    x2 = min(w, center_x + width_range)
    y1 = max(0, center_y - height_range)
    y2 = min(h, center_y + height_range)
    
    # æ ‡è®°ä¸­å¿ƒäººç‰©åŒºåŸŸ
    person_mask[y1:y2, x1:x2] = 255
    
    return person_mask

def create_edge_only_mask(img, border_size=0.15):
    """
    åˆ›å»ºåªåŒ…å«å›¾ç‰‡è¾¹ç¼˜åŒºåŸŸçš„ mask
    åªå¤„ç†è¾¹ç¼˜çš„æ°´å°ï¼Œé¿å…ä¸­å¿ƒäººç‰©åŒºåŸŸ
    
    Args:
        border_size: è¾¹ç¼˜å®½åº¦å å›¾ç‰‡çš„æ¯”ä¾‹ï¼ˆé»˜è®¤15%ï¼‰
    """
    h, w = img.shape[:2]
    mask = np.zeros((h, w), dtype=np.uint8)
    
    border_h = int(h * border_size)
    border_w = int(w * border_size)
    
    # ä¸Šè¾¹ç¼˜
    mask[0:border_h, :] = 255
    # ä¸‹è¾¹ç¼˜
    mask[h-border_h:h, :] = 255
    # å·¦è¾¹ç¼˜
    mask[:, 0:border_w] = 255
    # å³è¾¹ç¼˜
    mask[:, w-border_w:w] = 255
    
    return mask

def detect_repeating_text_pattern(image_path, pattern_texts=None, show_debug=False):
    """
    æ£€æµ‹é‡å¤å‡ºç°çš„æ°´å°æ–‡æœ¬æ¨¡å¼
    
    ç­–ç•¥ï¼š
    1. ä½¿ç”¨ OCR è¯†åˆ«æ‰€æœ‰æ–‡æœ¬
    2. æ‰¾åˆ°é‡å¤å‡ºç°çš„æ–‡æœ¬ç‰‡æ®µï¼ˆæ°´å°æ¨¡å¼ï¼‰
    3. æ ‡è®°æ‰€æœ‰åŒ¹é…è¯¥æ¨¡å¼çš„åŒºåŸŸ
    4. æ’é™¤äººç‰©ä¸­å¿ƒåŒºåŸŸ
    
    Args:
        pattern_texts: é¢„å®šä¹‰çš„æ°´å°æ–‡æœ¬æ¨¡å¼åˆ—è¡¨ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨æ£€æµ‹
        ä¾‹å¦‚ï¼š["æ»‘å‘—app", "1000ä¸‡", "é›ªå‹", "é€‰æ‹©", "é…’åº—", "æ•™ç»ƒ", "æ‘„å½±å¸ˆ", "çº¦ç©"]
    """
    try:
        import easyocr
    except ImportError:
        print("    âš ï¸  éœ€è¦ EasyOCR è¿›è¡Œæ¨¡å¼æ£€æµ‹")
        return None
    
    img = cv2.imread(image_path)
    if img is None:
        return None
    
    h, w = img.shape[:2]
    mask = np.zeros((h, w), dtype=np.uint8)
    
    # é¢„å®šä¹‰çš„æ°´å°æ–‡æœ¬æ¨¡å¼ï¼ˆå¸¸è§çš„æ»‘é›ªç±»æ°´å°ï¼‰
    if pattern_texts is None:
        pattern_texts = [
            "æ»‘å‘—", "app", "1000", "ä¸‡", "é›ªå‹", "é€‰æ‹©",
            "é…’åº—", "æ•™ç»ƒ", "æ‘„å½±å¸ˆ", "çº¦ç©", "é›ªç¥¨",
            "BDH"  # å¸¸è§çš„æ°´å°ç¼©å†™
        ]
    
    print(f"    è¯†åˆ«æ°´å°æ¨¡å¼: {', '.join(pattern_texts)}")
    
    # åˆå§‹åŒ– OCR
    reader = easyocr.Reader(['ch_sim', 'en'], gpu=False, verbose=False)
    results = reader.readtext(image_path)
    
    # è·å–äººç‰©åŒºåŸŸï¼ˆä½¿ç”¨ç²¾ç¡®ç­–ç•¥ï¼Œåªä¿æŠ¤æ ¸å¿ƒäººç‰©ï¼‰
    person_mask = detect_person_region(img, conservative=False)
    
    # ç»Ÿè®¡æ¯ä¸ªæ–‡æœ¬å‡ºç°çš„ä½ç½®
    matched_count = 0
    total_count = 0
    
    for (bbox, text, prob) in results:
        total_count += 1
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ°´å°æ¨¡å¼
        is_match = False
        for pattern in pattern_texts:
            if pattern.lower() in text.lower() or text.lower() in pattern.lower():
                is_match = True
                break
        
        if not is_match:
            continue
        
        # è·å–è¾¹ç•Œæ¡†åæ ‡
        pts = np.array(bbox, dtype=np.int32)
        center_x = int(np.mean(pts[:, 0]))
        center_y = int(np.mean(pts[:, 1]))
        
        # æ£€æŸ¥æ˜¯å¦åœ¨äººç‰©åŒºåŸŸ
        if person_mask[center_y, center_x] > 0:
            # äººç‰©åŒºåŸŸï¼Œè·³è¿‡
            continue
        
        # æ‰©å¤§è¾¹ç•Œæ¡†ï¼ˆè¦†ç›–å®Œæ•´æ–‡å­—å’Œé˜´å½±ï¼‰
        width = int(np.max(pts[:, 0]) - np.min(pts[:, 0]))
        height = int(np.max(pts[:, 1]) - np.min(pts[:, 1]))
        
        # æ‰©å¤§ 50% ç¡®ä¿è¦†ç›–ï¼ˆä» 80% é™ä½ï¼Œé¿å…è¿‡åº¦æ‰©å±•ï¼‰
        expand_ratio = 1.5
        new_width = int(width * expand_ratio)
        new_height = int(height * expand_ratio)
        
        x1 = max(0, center_x - new_width // 2)
        y1 = max(0, center_y - new_height // 2)
        x2 = min(w, center_x + new_width // 2)
        y2 = min(h, center_y + new_height // 2)
        
        # æ ‡è®°è¯¥åŒºåŸŸ
        cv2.rectangle(mask, (x1, y1), (x2, y2), 255, -1)
        matched_count += 1
        
        if show_debug:
            print(f"      åŒ¹é…åˆ°: '{text}' ä½ç½®:({center_x}, {center_y})")
    
    # æ¸©å’Œçš„è†¨èƒ€æ“ä½œï¼Œè¿æ¥ä¸´è¿‘çš„æ°´å°æ–‡å­—ï¼ˆé™ä½å¼ºåº¦ï¼‰
    if matched_count > 0:
        kernel = np.ones((10, 10), np.uint8)  # ä» 20Ã—20 é™ä½åˆ° 10Ã—10
        mask = cv2.dilate(mask, kernel, iterations=2)  # ä» 3 æ¬¡é™ä½åˆ° 2 æ¬¡
        
        # é‡è¦ï¼šè†¨èƒ€åå†æ¬¡æ’é™¤äººç‰©åŒºåŸŸï¼Œé˜²æ­¢æ‰©å±•åˆ°äººç‰©
        mask = cv2.bitwise_and(mask, cv2.bitwise_not(person_mask))
    
    print(f"    æ¨¡å¼åŒ¹é…: {matched_count}/{total_count} å¤„ (è·³è¿‡äººç‰©åŒºåŸŸ)")
    
    return mask

def detect_dark_text_on_white(img, show_debug=False):
    """
    æ£€æµ‹ç™½è‰²èƒŒæ™¯ï¼ˆé›ªåœ°ï¼‰ä¸Šçš„æ·±è‰²æ–‡å­—æ°´å°
    """
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape
    
    # æ£€æµ‹é«˜äº®åº¦åŒºåŸŸï¼ˆç™½è‰²/æµ…è‰²èƒŒæ™¯ï¼‰
    _, bright_areas = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
    
    # åœ¨äº®åŒºåŸŸä¸­æ£€æµ‹æ·±è‰²æ–‡å­—ï¼ˆè¾¹ç¼˜æ£€æµ‹ï¼‰
    edges = cv2.Canny(gray, 50, 150)
    
    # åªä¿ç•™åœ¨æ˜äº®åŒºåŸŸçš„è¾¹ç¼˜
    dark_text_mask = cv2.bitwise_and(edges, edges, mask=bright_areas)
    
    # å½¢æ€å­¦å¤„ç†ï¼šè¿æ¥æ–‡å­—ç¬”ç”»
    kernel_h = np.ones((2, 8), np.uint8)
    dark_text_mask = cv2.morphologyEx(dark_text_mask, cv2.MORPH_CLOSE, kernel_h)
    
    kernel_v = np.ones((8, 2), np.uint8)
    dark_text_mask = cv2.morphologyEx(dark_text_mask, cv2.MORPH_CLOSE, kernel_v)
    
    # è†¨èƒ€ä»¥è¦†ç›–å®Œæ•´æ–‡å­—
    kernel_dilate = np.ones((5, 5), np.uint8)
    dark_text_mask = cv2.dilate(dark_text_mask, kernel_dilate, iterations=2)
    
    # è¿‡æ»¤æ‰å¤ªå°æˆ–å¤ªå¤§çš„åŒºåŸŸ
    mask_filtered = np.zeros((h, w), dtype=np.uint8)
    contours, _ = cv2.findContours(dark_text_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    count = 0
    for contour in contours:
        area = cv2.contourArea(contour)
        if 100 < area < 8000:  # æ–‡å­—å¤§å°èŒƒå›´
            cv2.drawContours(mask_filtered, [contour], -1, 255, -1)
            count += 1
    
    if count > 0:
        print(f"    æ£€æµ‹åˆ°ç™½è‰²èƒŒæ™¯æ·±è‰²æ–‡å­—: {count} å¤„")
    
    return mask_filtered

def detect_specific_color_watermark(img, show_debug=False, exclude_person=True, edge_only=True):
    """
    æ£€æµ‹ç‰¹å®šé¢œè‰²çš„æ°´å°
    ç›®æ ‡é¢œè‰²: #67789d (RGB: 103, 120, 157) å’Œ #5e7da8 (RGB: 94, 125, 168)
    ä»¥åŠå„ç§ç°è“è‰²å˜ä½“ï¼ˆé€‚åº”ä¸åŒå…‰ç…§å’ŒèƒŒæ™¯ï¼‰
    
    Args:
        exclude_person: æ˜¯å¦æ’é™¤äººç‰©ä¸­å¿ƒåŒºåŸŸï¼Œé¿å…è¯¯ä¼¤è¡£æœä¸Šçš„å†…å®¹
        edge_only: æ˜¯å¦åªå¤„ç†è¾¹ç¼˜åŒºåŸŸçš„æ°´å°ï¼ˆæ¨èå¼€å¯ï¼‰
    """
    h, w = img.shape[:2]
    
    # è·å–äººç‰©åŒºåŸŸ maskï¼ˆç”¨äºæ’é™¤ï¼Œä½¿ç”¨ä¿å®ˆç­–ç•¥ï¼‰
    person_mask = detect_person_region(img, conservative=True) if exclude_person else np.zeros((h, w), dtype=np.uint8)
    
    # è·å–è¾¹ç¼˜åŒºåŸŸ maskï¼ˆåªå¤„ç†è¾¹ç¼˜ï¼‰
    edge_mask = create_edge_only_mask(img) if edge_only else np.ones((h, w), dtype=np.uint8) * 255
    
    if edge_only:
        print("    ä»…æ£€æµ‹è¾¹ç¼˜åŒºåŸŸæ°´å°ï¼Œä¿æŠ¤ä¸­å¿ƒäººç‰©")
    
    # å®šä¹‰ç›®æ ‡é¢œè‰²èŒƒå›´ï¼ˆBGRæ ¼å¼ï¼‰- å¢åŠ æ›´å¤šç°è“è‰²å˜ä½“
    target_colors = [
        {'name': '#67789d', 'bgr': np.array([157, 120, 103]), 'tolerance': 35},
        {'name': '#5e7da8', 'bgr': np.array([168, 125, 94]), 'tolerance': 35},
        {'name': 'gray-blue-1', 'bgr': np.array([140, 110, 95]), 'tolerance': 30},  # æ·±ç°è“
        {'name': 'gray-blue-2', 'bgr': np.array([180, 135, 110]), 'tolerance': 30},  # æµ…ç°è“
        {'name': 'gray-blue-3', 'bgr': np.array([150, 115, 90]), 'tolerance': 30},  # ä¸­ç°è“
    ]
    
    mask_combined = np.zeros((h, w), dtype=np.uint8)
    
    for color_info in target_colors:
        target_bgr = color_info['bgr']
        color_name = color_info['name']
        tolerance = color_info.get('tolerance', 30)
        
        # è®¾ç½®é¢œè‰²å®¹å·®ï¼ˆå…è®¸ä¸€å®šèŒƒå›´çš„é¢œè‰²åå·®ï¼‰
        lower = np.array([max(0, target_bgr[0] - tolerance), 
                         max(0, target_bgr[1] - tolerance), 
                         max(0, target_bgr[2] - tolerance)])
        upper = np.array([min(255, target_bgr[0] + tolerance), 
                         min(255, target_bgr[1] + tolerance), 
                         min(255, target_bgr[2] + tolerance)])
        
        # åˆ›å»ºé¢œè‰² mask
        mask_color = cv2.inRange(img, lower, upper)
        
        # åªä¿ç•™è¾¹ç¼˜åŒºåŸŸ
        mask_color = cv2.bitwise_and(mask_color, edge_mask)
        
        # æ’é™¤äººç‰©åŒºåŸŸ
        if exclude_person:
            mask_color = cv2.bitwise_and(mask_color, cv2.bitwise_not(person_mask))
        
        # ç»Ÿè®¡æ£€æµ‹åˆ°çš„åƒç´ 
        color_pixels = np.sum(mask_color > 0)
        if color_pixels > 100:  # åªæ˜¾ç¤ºæ˜æ˜¾æ£€æµ‹åˆ°çš„
            print(f"    æ£€æµ‹åˆ°é¢œè‰² {color_name}: {color_pixels} åƒç´ ")
        
        # å½¢æ€å­¦å¤„ç†ï¼šè¿æ¥æ–‡å­—ç¬”ç”»ï¼ˆåŠ å¼ºå¤„ç†ï¼‰
        kernel_h = np.ones((3, 10), np.uint8)  # æ¨ªå‘è¿æ¥ï¼ˆåŠ å¤§æ ¸ï¼‰
        mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_CLOSE, kernel_h)
        
        kernel_v = np.ones((10, 3), np.uint8)  # çºµå‘è¿æ¥ï¼ˆåŠ å¤§æ ¸ï¼‰
        mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_CLOSE, kernel_v)
        
        # è†¨èƒ€æ“ä½œï¼Œè¦†ç›–æ–‡å­—è¾¹ç¼˜
        kernel_dilate = np.ones((5, 5), np.uint8)
        mask_color = cv2.dilate(mask_color, kernel_dilate, iterations=2)
        
        # è¿‡æ»¤æ‰å¤ªå°å’Œå¤ªå¤§çš„åŒºåŸŸï¼ˆåªä¿ç•™æ–‡å­—å¤§å°ï¼‰
        contours, _ = cv2.findContours(mask_color, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for contour in contours:
            area = cv2.contourArea(contour)
            if 50 < area < 15000:  # æ‰©å¤§æ–‡å­—å¤§å°èŒƒå›´
                cv2.drawContours(mask_combined, [contour], -1, 255, -1)
    
    # æœ€ç»ˆè†¨èƒ€ï¼Œç¡®ä¿è¦†ç›–å®Œæ•´
    kernel = np.ones((3, 3), np.uint8)
    mask_combined = cv2.dilate(mask_combined, kernel, iterations=2)
    
    return mask_combined

def detect_watermark_by_text(image_path, show_debug=False, use_color_detection=True, use_pattern_match=True):
    """
    ä½¿ç”¨ OCR è¯†åˆ«ç‰¹å®šæ°´å°æ–‡å­—å¹¶ç²¾ç¡®æ ‡è®°
    å¯é€‰ï¼šç»“åˆç‰¹å®šé¢œè‰²æ£€æµ‹ + ç™½è‰²èƒŒæ™¯æ·±è‰²æ–‡å­—æ£€æµ‹ + æ¨¡å¼åŒ¹é…
    
    æ°´å°å…³é”®è¯ï¼š
    - æ»‘å‘—ã€appã€1000ä¸‡ã€é›ªå‹ã€é€‰æ‹©
    - é›ªç¥¨ã€é…’åº—ã€æ•™ç»ƒã€æ‘„å½±å¸ˆã€çº¦ç©
    
    Args:
        use_pattern_match: æ˜¯å¦ä½¿ç”¨é‡å¤æ¨¡å¼åŒ¹é…ï¼ˆæ¨èï¼‰â­
    
    éœ€è¦å®‰è£…: uv pip install easyocr
    """
    img = cv2.imread(image_path)
    
    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦è¯»å–æˆåŠŸ
    if img is None:
        print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶: {image_path}")
        return None, None
    
    h, w = img.shape[:2]
    
    # ============== 1. æ¨¡å¼åŒ¹é…å±‚ï¼ˆæ–°å¢ - æœ€ç²¾ç¡®ï¼‰â­ ==============
    mask_pattern = np.zeros((h, w), dtype=np.uint8)
    if use_pattern_match:
        print("  [1/4] é‡å¤æ¨¡å¼åŒ¹é…æ£€æµ‹ä¸­...")
        mask_pattern = detect_repeating_text_pattern(image_path, show_debug=show_debug)
        if mask_pattern is not None:
            pattern_pixels = np.sum(mask_pattern > 0)
            print(f"    æ¨¡å¼åŒ¹é…æ£€æµ‹åˆ° {pattern_pixels} åƒç´ ")
        else:
            mask_pattern = np.zeros((h, w), dtype=np.uint8)
    
    # ============== 2. é¢œè‰²æ£€æµ‹å±‚ï¼ˆè¾¹ç¼˜åŒºåŸŸçš„ç°è“è‰²æ°´å°ï¼‰==============
    mask_color = np.zeros((h, w), dtype=np.uint8)
    if use_color_detection:
        print("  [2/4] è¾¹ç¼˜åŒºåŸŸé¢œè‰²æ£€æµ‹ä¸­ (#67789d, #5e7da8)...")
        mask_color = detect_specific_color_watermark(img, show_debug, exclude_person=True, edge_only=True)
        color_pixels = np.sum(mask_color > 0)
        print(f"    é¢œè‰²æ£€æµ‹åˆ° {color_pixels} åƒç´ ")
    
    # ============== 3. ç™½è‰²èƒŒæ™¯æ·±è‰²æ–‡å­—æ£€æµ‹å±‚ï¼ˆé›ªåœ°æ°´å°ï¼‰==============
    print("  [3/4] ç™½è‰²èƒŒæ™¯æ·±è‰²æ–‡å­—æ£€æµ‹ä¸­...")
    mask_dark_on_white = detect_dark_text_on_white(img, show_debug)
    dark_pixels = np.sum(mask_dark_on_white > 0)
    if dark_pixels > 0:
        print(f"    ç™½è‰²èƒŒæ™¯æ£€æµ‹åˆ° {dark_pixels} åƒç´ ")
    
    # ============== 4. OCR æ–‡å­—è¯†åˆ«å±‚ï¼ˆç²¾ç¡®è¯†åˆ«ï¼‰==============
    mask_ocr = np.zeros((h, w), dtype=np.uint8)
    try:
        import easyocr
    except ImportError:
        print("  âš ï¸  OCR æ¨¡å—ä¸å¯ç”¨")
        if use_color_detection and np.sum(mask_color) > 0:
            print("  ä½¿ç”¨é¢œè‰²æ£€æµ‹ç»“æœ")
            return img, mask_color
        print("  âŒ éœ€è¦å®‰è£… EasyOCR æˆ–è‡³å°‘ä¸€ç§æ£€æµ‹æ–¹æ³•å¯ç”¨")
        print("     å®‰è£…å‘½ä»¤: source skiing/bin/activate && uv pip install easyocr")
        return None, None
    
    print("  [4/4] OCR æ–‡å­—è¯†åˆ«ä¸­ï¼ˆè¡¥å……æ£€æµ‹ï¼‰...")
    # åˆå§‹åŒ– OCRï¼Œæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡
    reader = easyocr.Reader(['ch_sim', 'en'], gpu=False, verbose=False)
    
    # æ£€æµ‹æ–‡å­—
    results = reader.readtext(image_path)
    
    # è·å–è¾¹ç¼˜åŒºåŸŸå’Œäººç‰©åŒºåŸŸ maskï¼ˆä¿å®ˆç­–ç•¥ï¼‰
    edge_mask = create_edge_only_mask(img, border_size=0.20)  # è¾¹ç¼˜20%
    person_mask = detect_person_region(img, conservative=True)
    
    # å®šä¹‰æ°´å°å…³é”®è¯ï¼ˆæ”¯æŒæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼‰
    watermark_patterns = [
        r'æ»‘å‘—',
        r'app',
        r'1000.*ä¸‡',
        r'é›ªå‹',
        r'é€‰æ‹©',
        r'é›ªç¥¨',
        r'é…’åº—',
        r'æ•™ç»ƒ',
        r'æ‘„å½±å¸ˆ',
        r'çº¦ç©',
        r'BDH',  # å¯èƒ½çš„è‹±æ–‡ç¼©å†™
    ]
    
    detected_watermarks = []
    
    for (bbox, text, prob) in results:
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…æ°´å°å…³é”®è¯
        is_watermark = False
        matched_keyword = None
        
        for pattern in watermark_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                is_watermark = True
                matched_keyword = pattern
                break
        
        if is_watermark and prob > 0.3:  # ç½®ä¿¡åº¦é˜ˆå€¼
            # è·å–è¾¹ç•Œæ¡†åæ ‡
            pts = np.array(bbox, dtype=np.int32)
            
            # æ‰©å¤§è¾¹ç•Œæ¡†ï¼Œç¡®ä¿å®Œå…¨è¦†ç›–æ–‡å­—ï¼ˆåŒ…æ‹¬è¾¹ç¼˜å’Œé˜´å½±ï¼‰
            # è®¡ç®—ä¸­å¿ƒç‚¹
            center_x = int(np.mean(pts[:, 0]))
            center_y = int(np.mean(pts[:, 1]))
            
            # æ£€æŸ¥æ˜¯å¦åœ¨è¾¹ç¼˜åŒºåŸŸæˆ–äººç‰©åŒºåŸŸä¹‹å¤–
            # å¦‚æœåœ¨äººç‰©åŒºåŸŸå†…ï¼Œè·³è¿‡
            if person_mask[center_y, center_x] > 0:
                print(f"    âš ï¸  è·³è¿‡äººç‰©åŒºåŸŸæ–‡å­—: '{text}'")
                continue
            
            # è®¡ç®—å®½é«˜
            width = int(np.max(pts[:, 0]) - np.min(pts[:, 0]))
            height = int(np.max(pts[:, 1]) - np.min(pts[:, 1]))
            
            # æ‰©å¤§ 50%ï¼ˆå¢åŠ æ‰©å±•æ¯”ä¾‹ä»¥è¦†ç›–è¾¹ç¼˜æ®‹ç•™ï¼‰
            expand_ratio = 1.5
            new_width = int(width * expand_ratio)
            new_height = int(height * expand_ratio)
            
            # åˆ›å»ºæ‰©å¤§åçš„çŸ©å½¢
            x1 = max(0, center_x - new_width // 2)
            y1 = max(0, center_y - new_height // 2)
            x2 = min(w, center_x + new_width // 2)
            y2 = min(h, center_y + new_height // 2)
            
            # å¡«å…… mask_ocr
            cv2.rectangle(mask_ocr, (x1, y1), (x2, y2), 255, -1)
            
            detected_watermarks.append({
                'text': text,
                'confidence': prob,
                'keyword': matched_keyword,
                'bbox': (x1, y1, x2, y2)
            })
            
            print(f"    âœ“ è¯†åˆ«åˆ°: '{text}' (ç½®ä¿¡åº¦: {prob:.2f}, åŒ¹é…: {matched_keyword})")
    
    print(f"    OCR è¯†åˆ«åˆ° {len(detected_watermarks)} å¤„æ°´å°æ–‡å­—")
    
    # å¯¹ OCR mask è¿›è¡Œè†¨èƒ€æ“ä½œï¼Œç¡®ä¿è¾¹ç¼˜å®Œå…¨è¦†ç›–
    if np.sum(mask_ocr) > 0:
        kernel = np.ones((15, 15), np.uint8)  # ä½¿ç”¨è¾ƒå¤§çš„æ ¸æ¥è†¨èƒ€
        mask_ocr = cv2.dilate(mask_ocr, kernel, iterations=2)
        print(f"    åº”ç”¨è¾¹ç¼˜æ‰©å±•ï¼Œç¡®ä¿å®Œå…¨è¦†ç›–æ–‡å­—æ®‹ç•™")
    
    # ============== åˆå¹¶å››ç§æ£€æµ‹ç»“æœ ==============
    print("\nåˆå¹¶æ£€æµ‹ç»“æœ...")
    
    # åˆå¹¶æ‰€æœ‰ mask ï¼ˆæ¨¡å¼åŒ¹é…ä¼˜å…ˆçº§æœ€é«˜ï¼‰
    final_mask = cv2.bitwise_or(mask_pattern, mask_color)
    final_mask = cv2.bitwise_or(final_mask, mask_ocr)
    final_mask = cv2.bitwise_or(final_mask, mask_dark_on_white)
    
    # ç»Ÿè®¡è¦†ç›–ç‡
    watermark_pixels = np.sum(final_mask > 0)
    total_pixels = h * w
    percentage = (watermark_pixels / total_pixels) * 100
    
    print(f"\næœ€ç»ˆæ£€æµ‹ç»“æœ:")
    print(f"  æ¨¡å¼åŒ¹é…: {np.sum(mask_pattern > 0)} åƒç´  â­")
    print(f"  è¾¹ç¼˜é¢œè‰²æ£€æµ‹: {np.sum(mask_color > 0)} åƒç´ ")
    print(f"  ç™½è‰²èƒŒæ™¯æ·±è‰²æ–‡å­—: {np.sum(mask_dark_on_white > 0)} åƒç´ ")
    print(f"  OCR è¡¥å……æ£€æµ‹: {np.sum(mask_ocr > 0)} åƒç´ ")
    print(f"  åˆå¹¶å: {watermark_pixels} åƒç´  ({percentage:.2f}%)")
    
    if watermark_pixels == 0:
        print("âš ï¸  æœªæ£€æµ‹åˆ°æ°´å°")
        return img, None
    
    if show_debug:
        # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
        debug_img = img.copy()
        
        # ç”¨ä¸åŒé¢œè‰²æ ‡è®°ä¸åŒæ¥æº
        debug_img[mask_color > 0] = [0, 255, 255]    # é»„è‰² = é¢œè‰²æ£€æµ‹
        debug_img[mask_ocr > 0] = [0, 255, 0]        # ç»¿è‰² = OCR
        
        # åœ¨å›¾ç‰‡ä¸Šæ ‡è®° OCR æ£€æµ‹åˆ°çš„æ–‡å­—æ¡†
        for wm in detected_watermarks:
            x1, y1, x2, y2 = wm['bbox']
            cv2.rectangle(debug_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        # æ˜¾ç¤º
        cv2.imshow("Original", cv2.resize(img, (800, 600)))
        cv2.imshow("Detection: Yellow=Color, Green=OCR", cv2.resize(debug_img, (800, 600)))
        cv2.imshow("Final Mask", cv2.resize(final_mask, (800, 600)))
        
        print("\nè°ƒè¯•ä¿¡æ¯:")
        print("  é»„è‰²åŒºåŸŸ = é¢œè‰²æ£€æµ‹ (#67789d, #5e7da8)")
        print("  ç»¿è‰²åŒºåŸŸ = OCR è¯†åˆ«çš„æ–‡å­—")
        print("\næŒ‰ä»»æ„é”®ç»§ç»­...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    return img, final_mask

def detect_watermark_hybrid(image_path, show_debug=False):
    """
    æ··åˆæ£€æµ‹æ¨¡å¼ï¼šç»“åˆ OCR + å›¾åƒç‰¹å¾ + é¢œè‰²æ£€æµ‹
    æœ€å…¨é¢çš„æ°´å°æ£€æµ‹æ–¹æ³•ï¼Œç‰¹åˆ«é€‚åˆåŠé€æ˜ã€è‰ºæœ¯å­—æ°´å°
    
    æ£€æµ‹ç­–ç•¥ï¼š
    1. OCR è¯†åˆ«æ–‡å­—ï¼ˆè¯†åˆ«æ¸…æ™°çš„æ–‡å­—ï¼‰
    2. æ£€æµ‹é‡å¤çš„æµ…è‰²æ–œçº¹ï¼ˆåŠé€æ˜æ°´å°ç‰¹å¾ï¼‰
    3. æ£€æµ‹ç‰¹å®šé¢œè‰²çš„æ–‡å­—ï¼ˆç°ç™½è‰²æ°´å°ï¼‰
    4. ç»“åˆä¸‰ç§æ–¹æ³•ï¼Œç”Ÿæˆç²¾ç¡®çš„æ°´å° mask
    """
    print("ä½¿ç”¨æ··åˆæ£€æµ‹æ¨¡å¼...")
    img = cv2.imread(image_path)
    
    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦è¯»å–æˆåŠŸ
    if img is None:
        print(f"âŒ é”™è¯¯: æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶: {image_path}")
        print("   è¯·æ£€æŸ¥:")
        print("   1. æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   2. æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("   3. æ–‡ä»¶æ ¼å¼æ˜¯å¦å—æ”¯æŒ")
        return None, None
    
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    h, w = gray.shape
    
    # åˆ›å»ºä¸‰ä¸ªæ£€æµ‹å±‚
    mask_ocr = np.zeros((h, w), dtype=np.uint8)
    mask_color = np.zeros((h, w), dtype=np.uint8)
    mask_pattern = np.zeros((h, w), dtype=np.uint8)
    
    # ============== æ–¹æ³•1: OCR æ–‡å­—è¯†åˆ« ==============
    try:
        import easyocr
        print("  [1/3] OCR æ–‡å­—è¯†åˆ«ä¸­...")
        reader = easyocr.Reader(['ch_sim', 'en'], gpu=False, verbose=False)
        results = reader.readtext(image_path)
        
        watermark_patterns = [
            r'æ»‘å‘—', r'app', r'1000.*ä¸‡', r'é›ªå‹', r'é€‰æ‹©',
            r'é›ªç¥¨', r'é…’åº—', r'æ•™ç»ƒ', r'æ‘„å½±å¸ˆ', r'çº¦ç©', r'BDH',
            r'å‹.*é€‰æ‹©', r'ä¸‡.*å‹'  # æ¨¡ç³ŠåŒ¹é…
        ]
        
        ocr_count = 0
        for (bbox, text, prob) in results:
            if prob > 0.2:  # é™ä½é˜ˆå€¼ï¼Œè¯†åˆ«æ›´å¤šå¯èƒ½çš„æ°´å°
                is_watermark = any(re.search(p, text, re.IGNORECASE) for p in watermark_patterns)
                if is_watermark:
                    pts = np.array(bbox, dtype=np.int32)
                    # æ‰©å¤§åŒºåŸŸï¼ˆä» 1.3 å¢åŠ åˆ° 1.5ï¼‰
                    center_x, center_y = int(np.mean(pts[:, 0])), int(np.mean(pts[:, 1]))
                    width = int((np.max(pts[:, 0]) - np.min(pts[:, 0])) * 1.5)
                    height = int((np.max(pts[:, 1]) - np.min(pts[:, 1])) * 1.5)
                    x1 = max(0, center_x - width // 2)
                    y1 = max(0, center_y - height // 2)
                    x2 = min(w, center_x + width // 2)
                    y2 = min(h, center_y + height // 2)
                    cv2.rectangle(mask_ocr, (x1, y1), (x2, y2), 255, -1)
                    ocr_count += 1
                    print(f"    âœ“ è¯†åˆ«åˆ°: '{text}' (ç½®ä¿¡åº¦: {prob:.2f})")
        
        # å¯¹ OCR mask è¿›è¡Œè†¨èƒ€æ“ä½œï¼Œç¡®ä¿è¾¹ç¼˜å®Œå…¨è¦†ç›–
        if ocr_count > 0:
            kernel = np.ones((15, 15), np.uint8)
            mask_ocr = cv2.dilate(mask_ocr, kernel, iterations=2)
        
        print(f"    OCR è¯†åˆ«åˆ° {ocr_count} å¤„æ°´å°æ–‡å­—")
    except ImportError:
        print("    âš ï¸  OCR ä¸å¯ç”¨ï¼Œè·³è¿‡")
    except Exception as e:
        print(f"    âš ï¸  OCR å‡ºé”™: {e}")
    
    # ============== æ–¹æ³•2: é¢œè‰²ç‰¹å¾æ£€æµ‹ï¼ˆæµ…è‰²åŠé€æ˜æ°´å°ï¼‰ ==============
    print("  [2/3] é¢œè‰²ç‰¹å¾æ£€æµ‹ä¸­...")
    
    # è½¬æ¢åˆ° HSV è‰²å½©ç©ºé—´ï¼Œæ›´å®¹æ˜“æ£€æµ‹ç‰¹å®šé¢œè‰²
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    
    # æ£€æµ‹æµ…è‰²/ç™½è‰²æ–‡å­—ï¼ˆé€šå¸¸æ˜¯ V é€šé“é«˜ï¼ŒS é€šé“ä½ï¼‰
    _, s, v = cv2.split(hsv)
    
    # é«˜äº®åº¦ã€ä½é¥±å’Œåº¦ = æµ…è‰²/ç™½è‰²æ°´å°
    _, high_brightness = cv2.threshold(v, 230, 255, cv2.THRESH_BINARY)
    _, low_saturation = cv2.threshold(s, 50, 255, cv2.THRESH_BINARY_INV)
    
    # ç»“åˆä¸¤è€…
    light_mask = cv2.bitwise_and(high_brightness, low_saturation)
    
    # æ£€æµ‹ç°è‰²æ–‡å­—ï¼ˆä¸­ç­‰äº®åº¦ï¼‰
    gray_range = cv2.inRange(v, 180, 230)
    
    # ç»“åˆæµ…è‰²å’Œç°è‰²æ£€æµ‹
    color_mask = cv2.bitwise_or(light_mask, gray_range)
    
    # å½¢æ€å­¦å¤„ç†ï¼šè¿æ¥æ–‡å­—ç¬”ç”»
    kernel_h = np.ones((2, 10), np.uint8)  # æ¨ªå‘è¿æ¥
    color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_CLOSE, kernel_h)
    
    kernel_v = np.ones((10, 2), np.uint8)  # çºµå‘è¿æ¥
    color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_CLOSE, kernel_v)
    
    # è¿‡æ»¤æ‰å¤ªå°å’Œå¤ªå¤§çš„åŒºåŸŸ
    contours, _ = cv2.findContours(color_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    color_count = 0
    for contour in contours:
        area = cv2.contourArea(contour)
        if 100 < area < 8000:  # æ–‡å­—å¤§å°èŒƒå›´
            # æ£€æŸ¥é•¿å®½æ¯”ï¼ˆæ–‡å­—é€šå¸¸æ˜¯ç»†é•¿çš„ï¼‰
            x, y, w_rect, h_rect = cv2.boundingRect(contour)
            aspect_ratio = max(w_rect, h_rect) / (min(w_rect, h_rect) + 1)
            if aspect_ratio < 15:  # ä¸æ˜¯æé•¿çš„çº¿æ¡
                cv2.drawContours(mask_color, [contour], -1, 255, -1)
                color_count += 1
    
    print(f"    é¢œè‰²æ£€æµ‹åˆ° {color_count} å¤„ç–‘ä¼¼æ°´å°åŒºåŸŸ")
    
    # ============== æ–¹æ³•3: é‡å¤æ¨¡å¼æ£€æµ‹ï¼ˆæ£€æµ‹é‡å¤çš„æ°´å°ï¼‰ ==============
    print("  [3/3] é‡å¤æ¨¡å¼æ£€æµ‹ä¸­...")
    
    # ä½¿ç”¨è¾¹ç¼˜æ£€æµ‹æ‰¾åˆ°æ–‡å­—è½®å»“
    edges = cv2.Canny(gray, 30, 100)
    
    # è†¨èƒ€è¾¹ç¼˜
    kernel = np.ones((2, 2), np.uint8)
    edges_dilated = cv2.dilate(edges, kernel, iterations=1)
    
    # åªä¿ç•™åœ¨æµ…è‰²åŒºåŸŸçš„è¾¹ç¼˜ï¼ˆæ°´å°ç‰¹å¾ï¼‰
    edges_in_light = cv2.bitwise_and(edges_dilated, light_mask)
    
    # è¿æ¥æ–‡å­—
    kernel_connect = np.ones((3, 8), np.uint8)
    pattern_mask = cv2.morphologyEx(edges_in_light, cv2.MORPH_CLOSE, kernel_connect)
    
    # è¿‡æ»¤å¤§å°
    contours, _ = cv2.findContours(pattern_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    pattern_count = 0
    for contour in contours:
        area = cv2.contourArea(contour)
        if 50 < area < 5000:
            cv2.drawContours(mask_pattern, [contour], -1, 255, -1)
            pattern_count += 1
    
    print(f"    æ¨¡å¼æ£€æµ‹åˆ° {pattern_count} å¤„ç–‘ä¼¼æ°´å°åŒºåŸŸ")
    
    # ============== åˆå¹¶ä¸‰ç§æ£€æµ‹ç»“æœ ==============
    print("\nåˆå¹¶æ£€æµ‹ç»“æœ...")
    
    # ä¼˜å…ˆä½¿ç”¨ OCR ç»“æœï¼ˆæœ€å‡†ç¡®ï¼‰
    final_mask = mask_ocr.copy()
    
    # æ·»åŠ é¢œè‰²æ£€æµ‹ç»“æœï¼ˆå»é™¤ä¸ OCR é‡å çš„éƒ¨åˆ†ï¼Œé¿å…è¿‡åº¦ä¿®å¤ï¼‰
    mask_color_filtered = cv2.bitwise_and(mask_color, cv2.bitwise_not(mask_ocr))
    final_mask = cv2.bitwise_or(final_mask, mask_color_filtered)
    
    # æ·»åŠ æ¨¡å¼æ£€æµ‹ç»“æœï¼ˆæœ€ä¿å®ˆï¼‰
    mask_pattern_filtered = cv2.bitwise_and(mask_pattern, cv2.bitwise_not(final_mask))
    final_mask = cv2.bitwise_or(final_mask, mask_pattern_filtered)
    
    # æœ€ç»ˆå½¢æ€å­¦ä¼˜åŒ–ï¼šè½»å¾®è†¨èƒ€ï¼Œç¡®ä¿è¦†ç›–å®Œæ•´
    kernel_final = np.ones((3, 3), np.uint8)
    final_mask = cv2.dilate(final_mask, kernel_final, iterations=1)
    
    # ç»Ÿè®¡
    watermark_pixels = np.sum(final_mask > 0)
    total_pixels = h * w
    percentage = (watermark_pixels / total_pixels) * 100
    
    print(f"\næœ€ç»ˆæ£€æµ‹ç»“æœ:")
    print(f"  æ°´å°åŒºåŸŸ: {watermark_pixels} åƒç´  ({percentage:.2f}%)")
    
    if show_debug:
        # æ˜¾ç¤ºå„å±‚æ£€æµ‹ç»“æœ
        debug_img = img.copy()
        
        # ç”¨ä¸åŒé¢œè‰²æ ‡è®°ä¸åŒæ¥æºçš„æ£€æµ‹
        debug_img[mask_ocr > 0] = [0, 255, 0]      # ç»¿è‰² = OCR
        debug_img[mask_color_filtered > 0] = [255, 255, 0]  # é’è‰² = é¢œè‰²
        debug_img[mask_pattern_filtered > 0] = [0, 165, 255]  # æ©™è‰² = æ¨¡å¼
        
        cv2.imshow("Original", cv2.resize(img, (800, 600)))
        cv2.imshow("Detection: Green=OCR, Cyan=Color, Orange=Pattern", 
                   cv2.resize(debug_img, (800, 600)))
        cv2.imshow("Final Mask", cv2.resize(final_mask, (800, 600)))
        
        # æ˜¾ç¤ºå„å±‚
        cv2.imshow("Layer 1: OCR", cv2.resize(mask_ocr, (400, 300)))
        cv2.imshow("Layer 2: Color", cv2.resize(mask_color, (400, 300)))
        cv2.imshow("Layer 3: Pattern", cv2.resize(mask_pattern, (400, 300)))
        
        print("\nè°ƒè¯•ä¿¡æ¯:")
        print("  ç»¿è‰²åŒºåŸŸ = OCR è¯†åˆ«çš„æ–‡å­—")
        print("  é’è‰²åŒºåŸŸ = é¢œè‰²æ£€æµ‹çš„æ°´å°")
        print("  æ©™è‰²åŒºåŸŸ = é‡å¤æ¨¡å¼æ£€æµ‹")
        print("\næŒ‰ä»»æ„é”®ç»§ç»­...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    return img, final_mask

def inpaint_with_ai(img, mask, method='lama'):
    """
    ä½¿ç”¨AIæ¨¡å‹è¿›è¡Œæ™ºèƒ½å›¾åƒä¿®å¤
    
    Args:
        img: è¾“å…¥å›¾ç‰‡ (BGRæ ¼å¼)
        mask: æ°´å°mask (ç°åº¦å›¾ï¼Œ255=éœ€è¦ä¿®å¤)
        method: ä¿®å¤æ–¹æ³• ('lama', 'cv2')
    
    Returns:
        ä¿®å¤åçš„å›¾ç‰‡
    """
    if method == 'lama' and LAMA_AVAILABLE:
        print("  ä½¿ç”¨ LaMa AI æ¨¡å‹ä¿®å¤...")
        try:
            # è½¬æ¢æ ¼å¼ï¼šBGR -> RGB
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img_pil = Image.fromarray(img_rgb)
            mask_pil = Image.fromarray(mask)
            
            # åˆå§‹åŒ–LaMaæ¨¡å‹
            model = ModelManager(
                name="lama",
                device="cpu",  # æˆ– "cuda" å¦‚æœæœ‰GPU
            )
            
            # é…ç½®å‚æ•°
            config = Config(
                ldm_steps=50,
                ldm_sampler=LDMSampler.ddim,
                hd_strategy=HDStrategy.ORIGINAL,
                hd_strategy_crop_margin=128,
                hd_strategy_crop_trigger_size=1280,
                hd_strategy_resize_limit=2048,
            )
            
            # æ‰§è¡Œä¿®å¤
            result = model(img_pil, mask_pil, config)
            
            # è½¬æ¢å›OpenCVæ ¼å¼
            result_bgr = cv2.cvtColor(np.array(result), cv2.COLOR_RGB2BGR)
            print("  âœ“ AI ä¿®å¤å®Œæˆ")
            return result_bgr
            
        except Exception as e:
            print(f"  âš ï¸  AI ä¿®å¤å¤±è´¥: {e}")
            print("  å›é€€åˆ°ä¼ ç»Ÿä¿®å¤æ–¹æ³•")
            method = 'cv2'
    
    # ä½¿ç”¨ä¼ ç»Ÿcv2.inpaintæ–¹æ³•
    if method == 'cv2' or not LAMA_AVAILABLE:
        # æ™ºèƒ½é€‰æ‹©ä¿®å¤åŠå¾„
        watermark_pixels = np.sum(mask > 0)
        total_pixels = mask.shape[0] * mask.shape[1]
        percentage = (watermark_pixels / total_pixels) * 100
        
        if percentage < 1:
            inpaint_radius = 10
            print(f"  ä½¿ç”¨ä¼ ç»Ÿä¿®å¤ï¼ˆç²¾ç»†æ¨¡å¼ï¼ŒåŠå¾„ {inpaint_radius}ï¼‰")
        elif percentage < 5:
            inpaint_radius = 8
            print(f"  ä½¿ç”¨ä¼ ç»Ÿä¿®å¤ï¼ˆæ ‡å‡†æ¨¡å¼ï¼ŒåŠå¾„ {inpaint_radius}ï¼‰")
        else:
            inpaint_radius = 5
            print(f"  ä½¿ç”¨ä¼ ç»Ÿä¿®å¤ï¼ˆä¿å®ˆæ¨¡å¼ï¼ŒåŠå¾„ {inpaint_radius}ï¼‰")
        
        # ä¸¤æ­¥ä¿®å¤
        result = cv2.inpaint(img, mask, inpaintRadius=inpaint_radius, flags=cv2.INPAINT_TELEA)
        
        if percentage < 5:
            kernel = np.ones((3, 3), np.uint8)
            mask_refined = cv2.erode(mask, kernel, iterations=1)
            if np.sum(mask_refined > 0) > 0:
                result = cv2.inpaint(result, mask_refined, inpaintRadius=inpaint_radius-2, flags=cv2.INPAINT_NS)
        
        return result

def remove_watermark(image_path, output_path=None, show_mask=False, use_ocr=False, use_hybrid=False, use_ai=True):
    """
    ç²¾ç¡®å»é™¤æ°´å°ï¼Œä¸å½±å“äººç‰©å’ŒèƒŒæ™¯
    
    Args:
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
        show_mask: æ˜¯å¦æ˜¾ç¤ºæ£€æµ‹åˆ°çš„æ°´å°åŒºåŸŸ
        use_ocr: æ˜¯å¦ä½¿ç”¨ OCR æ–‡å­—è¯†åˆ«æ¨¡å¼
        use_hybrid: æ˜¯å¦ä½¿ç”¨æ··åˆæ£€æµ‹æ¨¡å¼ï¼ˆæœ€å¼ºå¤§ï¼‰â­æ¨èâ­
        use_ai: æ˜¯å¦ä½¿ç”¨ AI æ¨¡å‹ä¿®å¤ï¼ˆLaMaï¼‰â­æ¨èâ­
    """
    print(f"å¤„ç†å›¾ç‰‡: {image_path}")
    
    # æ˜¾ç¤ºä¿®å¤æ–¹æ³•
    if use_ai and LAMA_AVAILABLE:
        print("ğŸ¨ ä¿®å¤æ–¹æ³•: LaMa AI æ¨¡å‹ (æ™ºèƒ½ä¿®å¤)")
    else:
        print("ğŸ”§ ä¿®å¤æ–¹æ³•: OpenCV ä¼ ç»Ÿä¿®å¤")
    
    if use_hybrid:
        print("â­ ä½¿ç”¨æ··åˆæ£€æµ‹æ¨¡å¼ï¼ˆOCR + å›¾åƒç‰¹å¾ + é¢œè‰²ï¼‰")
        img, mask = detect_watermark_hybrid(image_path, show_mask)
        mode_suffix = "_hybrid"
    elif use_ocr:
        print("ä½¿ç”¨ OCR æ–‡å­—è¯†åˆ«æ¨¡å¼...")
        img, mask = detect_watermark_by_text(image_path, show_mask)
        mode_suffix = "_ocr"
        if mask is None:
            print("OCR æ£€æµ‹å¤±è´¥ï¼Œåˆ‡æ¢åˆ°åŸºç¡€æ¨¡å¼")
            use_ocr = False
    
    if not use_hybrid and not use_ocr:
        print("ä½¿ç”¨åŸºç¡€æ£€æµ‹æ¨¡å¼...")
        img, mask = detect_watermark_mask(image_path)
        mode_suffix = "_cleaned"
        
        # ç»Ÿè®¡æ£€æµ‹åˆ°çš„æ°´å°åŒºåŸŸ
        watermark_pixels = np.sum(mask > 0)
        total_pixels = mask.shape[0] * mask.shape[1]
        percentage = (watermark_pixels / total_pixels) * 100
        
        print(f"æ£€æµ‹åˆ°æ°´å°åŒºåŸŸ: {watermark_pixels} åƒç´  ({percentage:.2f}% çš„å›¾ç‰‡)")
        
        if watermark_pixels == 0:
            print("âš ï¸  æœªæ£€æµ‹åˆ°æ°´å°åŒºåŸŸï¼Œå›¾ç‰‡ä¸éœ€è¦å¤„ç†")
            return image_path
        
        if percentage > 30:
            print("âš ï¸  è­¦å‘Šï¼šæ£€æµ‹åˆ°çš„åŒºåŸŸè¿‡å¤§ï¼Œå¯èƒ½ä¼šè¯¯ä¼¤å›¾ç‰‡å†…å®¹")
            print("å»ºè®®ä½¿ç”¨æ··åˆæ¨¡å¼ï¼ˆé€‰é¡¹ 7ï¼‰æˆ–é¢„è§ˆæ¨¡å¼æ£€æŸ¥")
        
        if show_mask:
            # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„æ°´å°åŒºåŸŸï¼ˆç”¨ç»¿è‰²æ ‡è®°ï¼‰
            debug_img = img.copy()
            debug_img[mask > 0] = [0, 255, 0]
            
            cv2.imshow("Original", cv2.resize(img, (800, 600)))
            cv2.imshow("Watermark Detection (Green)", cv2.resize(debug_img, (800, 600)))
            cv2.imshow("Mask", cv2.resize(mask, (800, 600)))
            print("\næ£€æµ‹åˆ°çš„æ°´å°åŒºåŸŸå·²ç”¨ç»¿è‰²æ ‡è®°")
            print("æŒ‰ä»»æ„é”®ç»§ç»­...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()
    
    if mask is None or np.sum(mask > 0) == 0:
        print("âš ï¸  æœªæ£€æµ‹åˆ°æ°´å°ï¼Œè·³è¿‡å¤„ç†")
        return image_path
    
    # ============== æ™ºèƒ½ä¿®å¤ï¼šä½¿ç”¨AIæ¨¡å‹æˆ–ä¼ ç»Ÿæ–¹æ³• ==============
    watermark_pixels = np.sum(mask > 0)
    total_pixels = mask.shape[0] * mask.shape[1]
    percentage = (watermark_pixels / total_pixels) * 100
    
    print(f"\nå¼€å§‹ä¿®å¤...")
    print(f"  æ°´å°è¦†ç›–ç‡: {percentage:.2f}%")
    
    # ä½¿ç”¨AIä¿®å¤æˆ–ä¼ ç»Ÿæ–¹æ³•
    if use_ai:
        result = inpaint_with_ai(img, mask, method='lama')
    else:
        result = inpaint_with_ai(img, mask, method='cv2')
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if output_path is None:
        base, ext = os.path.splitext(image_path)
        output_path = f"{base}{mode_suffix}{ext}"
    
    # ä¿å­˜ç»“æœ
    cv2.imwrite(output_path, result)
    print(f"âœ“ å®Œæˆï¼ä¿å­˜åˆ°: {output_path}")
    
    return output_path

def batch_remove_watermarks(image_dir, output_dir=None, use_ocr=False, use_hybrid=False):
    """
    æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
    
    Args:
        image_dir: å›¾ç‰‡ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        use_ocr: æ˜¯å¦ä½¿ç”¨ OCR æ¨¡å¼
        use_hybrid: æ˜¯å¦ä½¿ç”¨æ··åˆæ¨¡å¼
    """
    if output_dir is None:
        if use_hybrid:
            suffix = "cleaned_hybrid"
        elif use_ocr:
            suffix = "cleaned_ocr"
        else:
            suffix = "cleaned"
        output_dir = os.path.join(image_dir, suffix)
    
    os.makedirs(output_dir, exist_ok=True)
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    extensions = ('.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG')
    
    image_files = [f for f in os.listdir(image_dir) 
                   if f.endswith(extensions) and os.path.isfile(os.path.join(image_dir, f))]
    
    print(f"\næ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    if use_hybrid:
        mode_name = "æ··åˆæ£€æµ‹ï¼ˆOCR + å›¾åƒç‰¹å¾ + é¢œè‰²ï¼‰â­æ¨èâ­"
    elif use_ocr:
        mode_name = "OCR æ–‡å­—è¯†åˆ«"
    else:
        mode_name = "åŸºç¡€æ£€æµ‹"
    print(f"ä½¿ç”¨æ¨¡å¼: {mode_name}")
    
    for i, filename in enumerate(image_files, 1):
        print(f"\n{'='*70}")
        print(f"[{i}/{len(image_files)}] {filename}")
        print('='*70)
        
        input_path = os.path.join(image_dir, filename)
        output_path = os.path.join(output_dir, filename)
        
        try:
            remove_watermark(input_path, output_path, show_mask=False, 
                           use_ocr=use_ocr, use_hybrid=use_hybrid)
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\n{'='*70}")
    print(f"âœ“ å…¨éƒ¨å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")
    print('='*70)

if __name__ == "__main__":
    print("=" * 70)
    print("OpenCV æ°´å°å»é™¤å·¥å…· - æ™ºèƒ½æ£€æµ‹ï¼Œä¿æŠ¤ä¸»ä½“å…ƒç´ ")
    print("=" * 70)
    
    print("\né€‰æ‹©æ¨¡å¼ï¼š")
    print("â”" * 70)
    print("ã€åŸºç¡€æ¨¡å¼ã€‘- å¿«é€Ÿå¤„ç†")
    print("  1. å•å¼ å›¾ç‰‡")
    print("  2. æ‰¹é‡å¤„ç†")
    print("  3. é¢„è§ˆæ£€æµ‹æ•ˆæœ")
    print()
    print("ã€OCR æ¨¡å¼ã€‘- æ–‡å­—è¯†åˆ«")
    print("  4. å•å¼ å›¾ç‰‡")
    print("  5. æ‰¹é‡å¤„ç†")
    print("  6. é¢„è§ˆè¯†åˆ«æ•ˆæœ")
    print()
    print("ã€æ··åˆæ¨¡å¼ã€‘â­æœ€å¼ºâ­ - OCR + å›¾åƒç‰¹å¾ + é¢œè‰²æ£€æµ‹")
    print("  7. å•å¼ å›¾ç‰‡ (æ¨èé¦–é€‰)")
    print("  8. æ‰¹é‡å¤„ç† (æœ€å…¨é¢çš„å»æ°´å°)")
    print("  9. é¢„è§ˆæ£€æµ‹æ•ˆæœ (æŸ¥çœ‹ä¸‰å±‚æ£€æµ‹)")
    print("â”" * 70)
    
    choice = input("\nè¯·é€‰æ‹© (1-9): ").strip()
    
    # ä½¿ç”¨å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ä½œä¸ºåŸºç¡€è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    image_path = os.path.join(script_dir, "images/11-22/02.JPG")
    image_dir = os.path.join(script_dir, "images/11-22")
    
    # åŸºç¡€æ¨¡å¼
    if choice == "1":
        print("\nã€åŸºç¡€æ¨¡å¼ã€‘å•å¼ å›¾ç‰‡")
        remove_watermark(image_path, use_ocr=False, use_hybrid=False)
        
    elif choice == "2":
        print("\nã€åŸºç¡€æ¨¡å¼ã€‘æ‰¹é‡å¤„ç†")
        batch_remove_watermarks(image_dir, use_ocr=False, use_hybrid=False)
        
    elif choice == "3":
        print("\nã€åŸºç¡€æ¨¡å¼ã€‘é¢„è§ˆ")
        print("ç»¿è‰²æ ‡è®° = æ£€æµ‹åˆ°çš„æ°´å°åŒºåŸŸ")
        remove_watermark(image_path, show_mask=True, use_ocr=False, use_hybrid=False)
    
    # OCR æ¨¡å¼
    elif choice == "4":
        print("\nã€OCR æ¨¡å¼ã€‘å•å¼ å›¾ç‰‡")
        print("è¯†åˆ«å…³é”®è¯: æ»‘å‘—ã€appã€é›ªå‹ã€é›ªç¥¨ã€æ•™ç»ƒç­‰\n")
        remove_watermark(image_path, use_ocr=True, use_hybrid=False)
        
    elif choice == "5":
        print("\nã€OCR æ¨¡å¼ã€‘æ‰¹é‡å¤„ç†")
        batch_remove_watermarks(image_dir, use_ocr=True, use_hybrid=False)
        
    elif choice == "6":
        print("\nã€OCR æ¨¡å¼ã€‘é¢„è§ˆ")
        print("æ˜¾ç¤ºè¯†åˆ«åˆ°çš„æ–‡å­—å’Œè¾¹ç•Œæ¡†\n")
        remove_watermark(image_path, show_mask=True, use_ocr=True, use_hybrid=False)
    
    # æ··åˆæ¨¡å¼ â­æ¨èâ­
    elif choice == "7":
        print("\nâ­ã€æ··åˆæ¨¡å¼ã€‘å•å¼ å›¾ç‰‡ - æœ€å…¨é¢çš„æ°´å°æ£€æµ‹")
        print("ç»“åˆ:")
        print("  â€¢ OCR æ–‡å­—è¯†åˆ«")
        print("  â€¢ é¢œè‰²ç‰¹å¾æ£€æµ‹ï¼ˆæµ…è‰²/ç°è‰²æ°´å°ï¼‰")
        print("  â€¢ é‡å¤æ¨¡å¼æ£€æµ‹ï¼ˆè‰ºæœ¯å­—/åŠé€æ˜ï¼‰")
        print()
        remove_watermark(image_path, use_ocr=False, use_hybrid=True)
        
    elif choice == "8":
        print("\nâ­ã€æ··åˆæ¨¡å¼ã€‘æ‰¹é‡å¤„ç†")
        print("ä½¿ç”¨æœ€å¼ºæ£€æµ‹ç®—æ³•å¤„ç†æ‰€æœ‰å›¾ç‰‡\n")
        batch_remove_watermarks(image_dir, use_ocr=False, use_hybrid=True)
        
    elif choice == "9":
        print("\nâ­ã€æ··åˆæ¨¡å¼ã€‘é¢„è§ˆ - æŸ¥çœ‹ä¸‰å±‚æ£€æµ‹")
        print("é¢œè‰²è¯´æ˜:")
        print("  â€¢ ç»¿è‰² = OCR è¯†åˆ«çš„æ–‡å­—")
        print("  â€¢ é’è‰² = é¢œè‰²æ£€æµ‹çš„æ°´å°")
        print("  â€¢ æ©™è‰² = é‡å¤æ¨¡å¼æ£€æµ‹")
        print()
        remove_watermark(image_path, show_mask=True, use_ocr=False, use_hybrid=True)
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
    
    print("\n" + "â”" * 70)
    print("ğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("  â€¢ é¦–æ¬¡ä½¿ç”¨: é€‰æ‹©ã€9ã€‘é¢„è§ˆæ··åˆæ¨¡å¼æ£€æµ‹æ•ˆæœ")
    print("  â€¢ æ—¥å¸¸å¤„ç†: é€‰æ‹©ã€7ã€‘æ··åˆæ¨¡å¼å•å¼ æˆ–ã€8ã€‘æ‰¹é‡")
    print("  â€¢ å¿«é€Ÿå¤„ç†: é€‰æ‹©ã€1ã€‘åŸºç¡€æ¨¡å¼")
    print("  â€¢ ç²¾ç¡®è¯†åˆ«: é€‰æ‹©ã€4ã€‘OCR æ¨¡å¼ï¼ˆéœ€è¦ç½‘ç»œä¸‹è½½æ¨¡å‹ï¼‰")
    print("â”" * 70)

