#!/usr/bin/env python3
"""
æœ€ç»ˆæ­£ç¡®æ–¹æ¡ˆ - ç²¾å‡†æ£€æµ‹ + æ¸©å’Œä¿®å¤
æ ¸å¿ƒåŸåˆ™ï¼š
1. åªæ£€æµ‹æ°´å°æ–‡å­—ï¼ˆä¸æ˜¯æ•´ä¸ªåŒºåŸŸï¼‰
2. Maskåº”è¯¥<20%ï¼ˆè€Œä¸æ˜¯88.9%ï¼‰
3. é€‚ä¸­çš„strengthï¼ˆ0.96ï¼Œè€Œä¸æ˜¯0.99ï¼‰
4. ä¿æŠ¤æ‰€æœ‰éæ°´å°å…ƒç´ 
"""

import cv2
import numpy as np
from PIL import Image
import torch
from diffusers import StableDiffusionInpaintPipeline
import os
import easyocr

class PreciseWatermarkRemover:
    """ç²¾å‡†æ°´å°å»é™¤ - ä¿æŠ¤åŸå›¾"""
    
    def __init__(self, device=None):
        """åˆå§‹åŒ–"""
        if device is None:
            if torch.cuda.is_available():
                device = "cuda"
                dtype = torch.float16
            elif torch.backends.mps.is_available():
                device = "mps"
                dtype = torch.float32
            else:
                device = "cpu"
                dtype = torch.float32
        
        print(f"ğŸš€ åˆå§‹åŒ–æ¨¡å‹ï¼ˆè®¾å¤‡: {device}ï¼‰...")
        
        self.device = device
        self.dtype = dtype
        
        # åŠ è½½OCR
        print("   [1/2] åŠ è½½ EasyOCR...")
        self.ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu=(device == 'cuda'))
        
        # åŠ è½½SD
        print("   [2/2] åŠ è½½ SD Inpainting...")
        self.pipe = StableDiffusionInpaintPipeline.from_pretrained(
            "runwayml/stable-diffusion-inpainting",
            torch_dtype=dtype,
            safety_checker=None,
        )
        self.pipe = self.pipe.to(device)
        
        if device == "cuda":
            self.pipe.enable_attention_slicing()
        
        print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ\n")
    
    def detect_watermark_precise(self, image_path):
        """
        ç²¾å‡†æ£€æµ‹æ°´å° - åªæ£€æµ‹æ–‡å­—ï¼Œä¸æ£€æµ‹å…¶ä»–å…ƒç´ 
        
        ç­–ç•¥ï¼š
        1. OCRæ£€æµ‹æ–‡å­—ä½ç½®ï¼ˆåŸºç¡€ï¼‰
        2. é¢œè‰²æ£€æµ‹ç°è“è‰²æ–‡å­—ï¼ˆè¡¥å……ï¼‰
        3. ä¸¥æ ¼è¿‡æ»¤ï¼šåªä¿ç•™å°é¢ç§¯ã€é«˜é•¿å®½æ¯”çš„åŒºåŸŸï¼ˆæ–‡å­—ç‰¹å¾ï¼‰
        """
        print("ğŸ” ç²¾å‡†æ£€æµ‹æ°´å°æ–‡å­—...")
        
        img = cv2.imread(image_path)
        if img is None:
            return None
        
        h, w = img.shape[:2]
        mask_final = np.zeros((h, w), dtype=np.uint8)
        
        # ============== æ–¹æ³•1: OCRæ£€æµ‹ï¼ˆä¸»è¦æ–¹æ³•ï¼‰==============
        print("   [1/3] OCRæ£€æµ‹æ–‡å­—ä½ç½®...")
        
        ocr_results = self.ocr_reader.readtext(image_path)
        
        text_count = 0
        for bbox, text, conf in ocr_results:
            if conf < 0.3:  # ä½ç½®ä¿¡åº¦è·³è¿‡
                continue
            
            # è·å–è¾¹ç•Œæ¡†
            points = np.array(bbox, dtype=np.int32)
            x_min = max(0, points[:, 0].min() - 10)
            x_max = min(w, points[:, 0].max() + 10)
            y_min = max(0, points[:, 1].min() - 10)
            y_max = min(h, points[:, 1].max() + 10)
            
            # ç»˜åˆ¶çŸ©å½¢
            cv2.rectangle(mask_final, (x_min, y_min), (x_max, y_max), 255, -1)
            text_count += 1
            print(f"      æ£€æµ‹åˆ°: '{text}' (ç½®ä¿¡åº¦: {conf:.2f})")
        
        print(f"      OCRæ£€æµ‹: {text_count} ä¸ªæ–‡å­—åŒºåŸŸ")
        
        # ============== æ–¹æ³•2: å¢å¼ºé¢œè‰²æ£€æµ‹ï¼ˆå¤šç§ç°è‰²è°ƒï¼‰==============
        print("   [2/3] é¢œè‰²æ£€æµ‹å¤šç§ç°è‰²è°ƒæ°´å°...")
        
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        mask_color_all = np.zeros((h, w), dtype=np.uint8)
        
        # æ£€æµ‹å¤šç§é¢œè‰²çš„æ°´å°
        color_ranges = [
            # (åç§°, HSVä¸‹é™, HSVä¸Šé™)
            ("ç°è“è‰²", [90, 15, 70], [130, 180, 200]),
            ("æµ…ç°è‰²", [0, 0, 120], [180, 60, 200]),
            ("æ·±ç°è‰²", [0, 0, 60], [180, 100, 140]),
        ]
        
        color_total = 0
        for color_name, lower, upper in color_ranges:
            mask_range = cv2.inRange(hsv, np.array(lower), np.array(upper))
            
            # é¢å¤–çš„äº®åº¦è¿‡æ»¤ï¼ˆé¿å…è¯¯æ£€çº¯ç™½å’Œçº¯é»‘ï¼‰
            mask_range = cv2.bitwise_and(mask_range, cv2.inRange(gray, 80, 220))
            
            # å½¢æ€å­¦å¤„ç†
            kernel_small = np.ones((3, 3), np.uint8)
            mask_range = cv2.morphologyEx(mask_range, cv2.MORPH_CLOSE, kernel_small)
            
            # è¿‡æ»¤ï¼šåªä¿ç•™æ–‡å­—å½¢çŠ¶çš„åŒºåŸŸ
            contours, _ = cv2.findContours(mask_range, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            count = 0
            for contour in contours:
                area = cv2.contourArea(contour)
                
                # æ–‡å­—ç‰¹å¾ï¼šé¢ç§¯åœ¨80-8000ä¹‹é—´ï¼ˆæ”¾å®½èŒƒå›´ï¼‰
                if area < 80 or area > 8000:
                    continue
                
                # è®¡ç®—é•¿å®½æ¯”
                x, y, w_box, h_box = cv2.boundingRect(contour)
                aspect_ratio = max(w_box, h_box) / max(min(w_box, h_box), 1)
                
                # æ–‡å­—ç‰¹å¾ï¼šé•¿å®½æ¯” > 1.3ï¼ˆæ”¾å®½ï¼‰
                if aspect_ratio < 1.3:
                    continue
                
                # ä¿ç•™æ­¤åŒºåŸŸ
                cv2.drawContours(mask_color_all, [contour], -1, 255, -1)
                count += 1
            
            if count > 0:
                print(f"      {color_name}: {count} ä¸ªåŒºåŸŸ")
                color_total += count
        
        # åˆå¹¶åˆ°æ€»mask
        mask_final = cv2.bitwise_or(mask_final, mask_color_all)
        
        print(f"      é¢œè‰²æ£€æµ‹æ€»è®¡: {color_total} ä¸ªæ°´å°åŒºåŸŸ")
        
        # ============== æ–¹æ³•3: æ‰©å±•Maskï¼ˆè¿æ¥é™„è¿‘çš„æ–‡å­—ï¼‰==============
        print("   [3/3] æ‰©å±•å¹¶è¿æ¥æ°´å°åŒºåŸŸ...")
        
        # é€‚åº¦è†¨èƒ€ï¼ˆè¦†ç›–æ–‡å­—è¾¹ç¼˜ï¼‰
        kernel_dilate = np.ones((7, 7), np.uint8)
        mask_final = cv2.dilate(mask_final, kernel_dilate, iterations=2)
        
        # é—­è¿ç®—ï¼ˆå¡«å……æ–‡å­—å†…éƒ¨çš„ç©ºæ´ï¼‰
        kernel_close = np.ones((10, 10), np.uint8)
        mask_final = cv2.morphologyEx(mask_final, cv2.MORPH_CLOSE, kernel_close)
        
        # ä¿æŠ¤æ ¸å¿ƒäººç‰©åŒºåŸŸï¼ˆæ‰©å¤§ä¿æŠ¤èŒƒå›´ï¼‰
        center_x, center_y = w // 2, h // 2
        
        # ä¿æŠ¤äººè„¸æ ¸å¿ƒï¼ˆ8% x 10%ï¼‰
        face_w, face_h = int(w * 0.08), int(h * 0.10)
        mask_final[
            max(0, center_y-face_h):min(h, center_y+face_h),
            max(0, center_x-face_w):min(w, center_x+face_w)
        ] = 0
        
        # ä¿æŠ¤èº«ä½“æ ¸å¿ƒï¼ˆ12% x 20%ï¼‰
        body_w, body_h = int(w * 0.12), int(h * 0.20)
        mask_final[
            max(0, center_y):min(h, center_y+body_h),
            max(0, center_x-body_w):min(w, center_x+body_w)
        ] = 0
        
        mask_filtered = mask_final
        
        # ç»Ÿè®¡
        total_pixels = np.sum(mask_filtered > 0)
        percentage = (total_pixels / (h * w)) * 100
        
        print(f"\n   âœ“ æœ€ç»ˆæ£€æµ‹ç»“æœ:")
        print(f"      æ°´å°åŒºåŸŸ: {total_pixels:,} åƒç´  ({percentage:.1f}%)")
        
        if percentage > 30:
            print(f"      âš ï¸  è­¦å‘Š: æ°´å°åŒºåŸŸè¿‡å¤§ï¼ˆ>{30}%ï¼‰ï¼Œå¯èƒ½è¯¯æ£€ï¼")
        elif percentage < 2:
            print(f"      âš ï¸  è­¦å‘Š: æ°´å°åŒºåŸŸè¿‡å°ï¼ˆ<{2}%ï¼‰ï¼Œå¯èƒ½æ¼æ£€ï¼")
        else:
            print(f"      âœ“ æ°´å°åŒºåŸŸåˆç†")
        
        return mask_filtered
    
    def remove_watermark_tiled(self, image_path, mask=None, output_path=None,
                               num_inference_steps=50, strength=0.94, tile_size=300):
        """
        åˆ†å—ä¿®å¤ç­–ç•¥ - è§£å†³å¯†é›†æ°´å°é—®é¢˜
        
        å°†å›¾ç‰‡åˆ†æˆå¤šä¸ªtileï¼Œæ¯ä¸ªtileå•ç‹¬ä¿®å¤ï¼Œé¿å…å•æ¬¡ä¿®å¤èŒƒå›´è¿‡å¤§
        
        Args:
            strength: 0.94 = å¹³è¡¡ä¿®å¤
            tile_size: æ¯ä¸ªtileçš„å¤§å°ï¼ˆåƒç´ ï¼‰
        """
        # è¯»å–å›¾ç‰‡
        image = Image.open(image_path).convert("RGB")
        original_size = image.size
        w, h = original_size
        
        # è‡ªåŠ¨æ£€æµ‹æ°´å°
        if mask is None:
            mask_np = self.detect_watermark_precise(image_path)
            if mask_np is None:
                print("âŒ æ°´å°æ£€æµ‹å¤±è´¥")
                return None, None
        else:
            if isinstance(mask, np.ndarray):
                mask_np = mask
            else:
                mask_np = np.array(mask)
        
        # æ£€æŸ¥maskå¤§å°
        mask_ratio = np.sum(mask_np > 0) / (mask_np.shape[0] * mask_np.shape[1])
        
        # ç”Ÿæˆé»˜è®¤output_path
        if output_path is None:
            base, ext = os.path.splitext(image_path)
            output_path = f"{base}_final{ext}"
        
        # å¦‚æœmaskå¤ªå¤§ï¼Œä½¿ç”¨åˆ†å—ç­–ç•¥
        if mask_ratio > 0.4:
            print(f"\nğŸ’¡ æ£€æµ‹åˆ°å¯†é›†æ°´å°ï¼ˆ{mask_ratio*100:.1f}%ï¼‰ï¼Œå¯ç”¨åˆ†å—ä¿®å¤ç­–ç•¥...")
            return self._remove_watermark_tiled_impl(
                image, mask_np, output_path, num_inference_steps, strength, tile_size
            )
        else:
            # maskä¸å¤§ï¼Œç›´æ¥ä¿®å¤
            print(f"\nâœ“ æ°´å°è¦†ç›–ç‡{mask_ratio*100:.1f}%ï¼Œä½¿ç”¨æ ‡å‡†ä¿®å¤...")
            return self._remove_watermark_standard(
                image, mask_np, output_path, num_inference_steps, strength
            )
    
    def _remove_watermark_tiled_impl(self, image_pil, mask_np, output_path, 
                                     num_inference_steps, strength, tile_size):
        """åˆ†å—ä¿®å¤å®ç°"""
        import numpy as np
        from PIL import Image
        
        w, h = image_pil.size
        image_np = np.array(image_pil)
        result_np = image_np.copy()
        
        # è®¡ç®—tileæ•°é‡
        tiles_x = (w + tile_size - 1) // tile_size
        tiles_y = (h + tile_size - 1) // tile_size
        
        print(f"   åˆ†å—ç­–ç•¥: {tiles_x}x{tiles_y} = {tiles_x*tiles_y}ä¸ªåŒºå—")
        print(f"   æ¯ä¸ªåŒºå—: {tile_size}x{tile_size}åƒç´ \n")
        
        processed_count = 0
        total_tiles = tiles_x * tiles_y
        
        # è®¡ç®—å®é™…éœ€è¦å¤„ç†çš„tileæ•°é‡ï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦ï¼‰
        tiles_to_process = []
        for ty in range(tiles_y):
            for tx in range(tiles_x):
                x1 = tx * tile_size
                y1 = ty * tile_size
                x2 = min(x1 + tile_size, w)
                y2 = min(y1 + tile_size, h)
                tile_mask = mask_np[y1:y2, x1:x2]
                if np.sum(tile_mask > 0) / (tile_mask.size) >= 0.01:
                    tiles_to_process.append((tx, ty))
        
        total_active_tiles = len(tiles_to_process)
        print(f"   é¢„è®¡å¤„ç†: {total_active_tiles} ä¸ªå«æœ‰æ°´å°çš„åŒºå—")
        
        for i, (tx, ty) in enumerate(tiles_to_process):
            processed_count += 1
            
            # è®¡ç®—å½“å‰tileçš„èŒƒå›´
            x1 = tx * tile_size
            y1 = ty * tile_size
            x2 = min(x1 + tile_size, w)
            y2 = min(y1 + tile_size, h)
            
            # æå–å½“å‰tileçš„mask
            tile_mask = mask_np[y1:y2, x1:x2]
            tile_mask_ratio = np.sum(tile_mask > 0) / (tile_mask.size)
            
            print(f"   [{processed_count}/{total_active_tiles}] å¤„ç†åŒºå— ({tx},{ty}) æ°´å°å æ¯”{tile_mask_ratio*100:.1f}% ... ", end="", flush=True)
            
            # æå–tileå›¾åƒ
            tile_image = image_np[y1:y2, x1:x2]
            tile_image_pil = Image.fromarray(tile_image)
            tile_mask_pil = Image.fromarray(tile_mask)
            
            # è°ƒæ•´å°ºå¯¸åˆ°8çš„å€æ•°
            tile_w, tile_h = tile_image_pil.size
            new_w = (tile_w // 8) * 8
            new_h = (tile_h // 8) * 8
            
            if new_w < 64 or new_h < 64:
                print("è·³è¿‡ï¼ˆåŒºå—å¤ªå°ï¼‰")
                continue
            
            tile_image_resized = tile_image_pil.resize((new_w, new_h), Image.LANCZOS)
            tile_mask_resized = tile_mask_pil.resize((new_w, new_h), Image.LANCZOS)
            
            # SDä¿®å¤
            prompt = """exact same content, preserve original, only remove text,
                        match surrounding colors and textures perfectly"""
            
            negative_prompt = """text, watermark, any changes, new elements, blurry"""
            
            try:
                # å¯ç”¨å†…éƒ¨è¿›åº¦æ¡ï¼Œè®©ç”¨æˆ·çœ‹åˆ°æ¯ä¸€å—çš„è¿›åº¦
                self.pipe.set_progress_bar_config(disable=False)
                print(f"\n   ğŸš€ æ­£åœ¨ä¿®å¤åŒºå— [{processed_count}/{total_active_tiles}]...")
                
                tile_result = self.pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    image=tile_image_resized,
                    mask_image=tile_mask_resized,
                    num_inference_steps=20,  # é™ä½åˆ°20æ­¥ï¼Œå¤§å¹…æé€Ÿ
                    guidance_scale=5.5,
                    strength=min(0.95, strength + 0.02),
                ).images[0]
                
                # æ¢å¤å°ºå¯¸
                if tile_result.size != (tile_w, tile_h):
                    tile_result = tile_result.resize((tile_w, tile_h), Image.LANCZOS)
                
                # å†™å›result
                result_np[y1:y2, x1:x2] = np.array(tile_result)
                print("âœ… å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")
                continue
        
        print(f"\nâœ“ åˆ†å—ä¿®å¤å®Œæˆï¼å…±å¤„ç†{processed_count}ä¸ªåŒºå—\n")
        
        # ä¿å­˜ç»“æœ
        result_pil = Image.fromarray(result_np)
        
        if output_path is None:
            base, ext = os.path.splitext(str(image_pil.filename) if hasattr(image_pil, 'filename') else "output.jpg")
            output_path = f"{base}_final{ext}"
        
        result_pil.save(output_path, quality=95)
        print(f"âœ“ ä¿å­˜åˆ°: {output_path}\n")
        
        return result_pil, output_path
    
    def _remove_watermark_standard(self, image_pil, mask_np, output_path,
                                   num_inference_steps, strength):
        """æ ‡å‡†ä¿®å¤å®ç°"""
        original_size = image_pil.size
        
        # è½¬æ¢ mask
        mask_pil = Image.fromarray(mask_np).convert("L")
        mask_pil = mask_pil.resize(original_size, Image.LANCZOS)
        
        # è°ƒæ•´å°ºå¯¸
        def resize_to_multiple_of_8(img):
            w, h = img.size
            new_w = (w // 8) * 8
            new_h = (h // 8) * 8
            return img.resize((new_w, new_h), Image.LANCZOS)
        
        image_resized = resize_to_multiple_of_8(image_pil)
        mask_resized = resize_to_multiple_of_8(mask_pil)
        
        print(f"\nğŸ¨ å¼€å§‹ AI ä¿®å¤...")
        print(f"   åŸå§‹å°ºå¯¸: {original_size}")
        print(f"   å¤„ç†å°ºå¯¸: {image_resized.size}")
        print(f"   æ¨ç†æ­¥æ•°: {num_inference_steps}")
        print(f"   ä¿®å¤å¼ºåº¦: {strength} ï¼ˆä¿å®ˆæ¨¡å¼ - ä¸¥æ ¼ä¿æŠ¤åŸå›¾ï¼‰")
        
        # ä¼˜åŒ–çš„æç¤ºè¯ - æåº¦å¼ºè°ƒä¿æŒåŸæ ·
        prompt = """exact same person, same face, same clothes, same pose, same everything,
                    preserve all original elements, only remove text overlay,
                    keep original background colors and textures,
                    inpaint only watermarked areas with matching background,
                    photorealistic, high quality"""
        
        negative_prompt = """text, watermark, logo, words, letters, chinese characters, stamps,
                            any changes to person, different face, different clothes, new elements,
                            different pose, different background, added objects, goggles change,
                            helmet change, cloth color change, face modification,
                            blurry, artifacts, distorted, unrealistic"""
        
        # SD Inpainting - ä¿å®ˆæ¨¡å¼
        result = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=image_resized,
            mask_image=mask_resized,
            num_inference_steps=num_inference_steps,
            guidance_scale=6.0,  # é™ä½å¼•å¯¼å¼ºåº¦ï¼Œå‡å°‘åˆ›é€ æ€§ä¿®æ”¹
            strength=strength,  # ä¿å®ˆä¿®å¤
        ).images[0]
        
        # æ¢å¤å°ºå¯¸
        if result.size != original_size:
            result = result.resize(original_size, Image.LANCZOS)
        
        # ä¿å­˜ç»“æœ
        if output_path is None:
            output_path = "output_final.jpg"
        
        result.save(output_path, quality=95)
        print(f"\nâœ“ ä¿®å¤å®Œæˆï¼ä¿å­˜åˆ°: {output_path}\n")
        
        return result, output_path


def main():
    """ä¸»ç¨‹åº"""
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: uv run python remove_watermark_final.py <å›¾ç‰‡è·¯å¾„> [æ­¥æ•°] [å¼ºåº¦]")
        print("\nç¤ºä¾‹:")
        print("  æ ‡å‡†: uv run python remove_watermark_final.py image.jpg")
        print("  é«˜è´¨é‡: uv run python remove_watermark_final.py image.jpg 70")
        print("  è‡ªå®šä¹‰: uv run python remove_watermark_final.py image.jpg 50 0.96")
        print("\nå‚æ•°è¯´æ˜:")
        print("  æ­¥æ•°: 30-100 (é»˜è®¤50)")
        print("  å¼ºåº¦: 0.90-0.98 (é»˜è®¤0.96ï¼Œä¿æŠ¤åŸå›¾)")
        return
    
    image_path = sys.argv[1]
    num_steps = int(sys.argv[2]) if len(sys.argv) > 2 else 50
    strength = float(sys.argv[3]) if len(sys.argv) > 3 else 0.96
    
    if not os.path.exists(image_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    print("=" * 70)
    print("ğŸ¯ ç²¾å‡†æ°´å°å»é™¤å·¥å…·")
    print(f"   æ¨¡å¼: æ¸©å’Œä¿®å¤ (strength={strength})")
    print(f"   æ­¥æ•°: {num_steps}")
    print("   ç­–ç•¥: ç²¾å‡†æ£€æµ‹ + ä¿æŠ¤åŸå›¾")
    print("=" * 70)
    print()
    
    # åˆå§‹åŒ–
    remover = PreciseWatermarkRemover()
    
    # å¤„ç†
    remover.remove_watermark_tiled(
        image_path,
        num_inference_steps=num_steps,
        strength=strength
    )
    
    print("=" * 70)
    print("âœ“ å…¨éƒ¨å®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    main()

