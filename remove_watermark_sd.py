#!/usr/bin/env python3
"""
ä½¿ç”¨ Stable Diffusion Inpainting å½»åº•å»é™¤æ°´å°
æœ€å¼ºå¤§çš„ AI å›¾åƒä¿®å¤æ–¹æ¡ˆ - ä¸€æ¬¡æ€§è§£å†³æ‰€æœ‰æ°´å°é—®é¢˜

ä¼˜åŠ¿ï¼š
1. æ·±åº¦ç†è§£å›¾åƒå†…å®¹ï¼Œç”Ÿæˆè‡ªç„¶çº¹ç†
2. å®Œç¾å¤„ç†å¤šå±‚å åŠ ã€åŠé€æ˜æ°´å°
3. ä¿æŠ¤äººç‰©ç»†èŠ‚ï¼Œä¸ä¼šæ¨¡ç³Šè„¸éƒ¨
4. æ•ˆæœæ¥è¿‘ä¸“ä¸šä¿®å›¾å¸ˆæ°´å¹³
"""

import cv2
import numpy as np
from PIL import Image
import torch
from diffusers import StableDiffusionInpaintPipeline
import os
from pathlib import Path

class SDWatermarkRemover:
    """åŸºäº Stable Diffusion çš„æ™ºèƒ½æ°´å°å»é™¤å™¨"""
    
    def __init__(self, model_id="runwayml/stable-diffusion-inpainting", device=None):
        """
        åˆå§‹åŒ– SD Inpainting æ¨¡å‹
        
        Args:
            model_id: Hugging Face æ¨¡å‹ ID
            device: 'cuda', 'mps' (Mac M1/M2), æˆ– 'cpu'
        """
        if device is None:
            if torch.cuda.is_available():
                device = "cuda"
                dtype = torch.float16
            elif torch.backends.mps.is_available():
                device = "mps"
                dtype = torch.float32  # MPS å¯¹ float16 æ”¯æŒä¸å®Œæ•´
            else:
                device = "cpu"
                dtype = torch.float32
        
        print(f"ğŸš€ åˆå§‹åŒ– Stable Diffusion Inpainting æ¨¡å‹...")
        print(f"   è®¾å¤‡: {device}")
        print(f"   ç²¾åº¦: {dtype}")
        print(f"   æ¨¡å‹: {model_id}")
        
        self.device = device
        self.dtype = dtype
        
        # åŠ è½½æ¨¡å‹
        self.pipe = StableDiffusionInpaintPipeline.from_pretrained(
            model_id,
            torch_dtype=dtype,
            safety_checker=None,  # å…³é—­å®‰å…¨æ£€æŸ¥åŠ é€Ÿ
        )
        self.pipe = self.pipe.to(device)
        
        # ä¼˜åŒ–è®¾ç½®
        if device == "cuda":
            self.pipe.enable_attention_slicing()  # å‡å°‘æ˜¾å­˜ä½¿ç”¨
            # self.pipe.enable_xformers_memory_efficient_attention()  # å¯é€‰ï¼šéœ€è¦å®‰è£… xformers
        
        print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆï¼\n")
    
    def detect_watermark_auto(self, image_path):
        """
        è‡ªåŠ¨æ£€æµ‹æ°´å°åŒºåŸŸ
        ç»“åˆå¤šç§æ–¹æ³•ï¼šé¢œè‰²æ£€æµ‹ + è¾¹ç¼˜æ£€æµ‹ + ä½ç½®æ¨æ–­
        """
        print(f"ğŸ“· åˆ†æå›¾ç‰‡: {image_path}")
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        
        h, w = img.shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # æ–¹æ³•1: æ£€æµ‹ç°è“è‰²æ°´å°ï¼ˆå¤©ç©ºèƒŒæ™¯ï¼‰
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # ç°è“è‰²èŒƒå›´ï¼ˆæ°´å°å¸¸ç”¨é¢œè‰²ï¼‰
        lower_gray_blue = np.array([90, 20, 80])
        upper_gray_blue = np.array([130, 150, 200])
        mask_color = cv2.inRange(hsv, lower_gray_blue, upper_gray_blue)
        
        # æ–¹æ³•2: æ£€æµ‹ç™½è‰²é›ªåœ°ä¸Šçš„æ·±è‰²æ–‡å­—
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, bright_areas = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
        edges = cv2.Canny(gray, 50, 150)
        mask_dark_text = cv2.bitwise_and(edges, bright_areas)
        
        # æ–¹æ³•3: è¾¹ç¼˜åŒºåŸŸå¢å¼ºæ£€æµ‹ï¼ˆæ°´å°é€šå¸¸åœ¨å››å‘¨ï¼‰
        border_size = int(min(h, w) * 0.15)
        edge_mask = np.zeros((h, w), dtype=np.uint8)
        edge_mask[0:border_size, :] = 255  # ä¸Š
        edge_mask[h-border_size:h, :] = 255  # ä¸‹
        edge_mask[:, 0:border_size] = 255  # å·¦
        edge_mask[:, w-border_size:w] = 255  # å³
        
        # åˆå¹¶æ£€æµ‹ç»“æœ
        mask = cv2.bitwise_or(mask_color, mask_dark_text)
        
        # åœ¨è¾¹ç¼˜åŒºåŸŸåŠ å¼ºæ£€æµ‹
        mask_edge_enhanced = cv2.bitwise_and(mask, edge_mask)
        mask = cv2.bitwise_or(mask, mask_edge_enhanced)
        
        # å½¢æ€å­¦å¤„ç†ï¼šè¿æ¥æ–‡å­—ç¬”ç”»
        kernel = np.ones((15, 15), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.dilate(mask, kernel, iterations=3)
        
        # ä¿æŠ¤ä¸­å¿ƒäººç‰©åŒºåŸŸï¼ˆé¿å…è¯¯æ£€ï¼‰
        center_x, center_y = w // 2, h // 2
        person_w, person_h = int(w * 0.3), int(h * 0.4)
        x1 = max(0, center_x - person_w // 2)
        x2 = min(w, center_x + person_w // 2)
        y1 = max(0, center_y - person_h // 2)
        y2 = min(h, center_y + person_h // 2)
        mask[y1:y2, x1:x2] = 0  # æ¸…é™¤äººç‰©åŒºåŸŸ
        
        # ç»Ÿè®¡
        watermark_pixels = np.sum(mask > 0)
        percentage = (watermark_pixels / (h * w)) * 100
        print(f"   æ£€æµ‹åˆ°æ°´å°åŒºåŸŸ: {watermark_pixels:,} åƒç´  ({percentage:.1f}%)")
        
        return mask
    
    def remove_watermark(self, image_path, mask=None, output_path=None, 
                        prompt="high quality photo, natural, no watermark, clean",
                        negative_prompt="watermark, text, logo, blurry, low quality",
                        num_inference_steps=50,
                        guidance_scale=7.5):
        """
        ä½¿ç”¨ SD Inpainting å»é™¤æ°´å°
        
        Args:
            image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
            mask: æ°´å° maskï¼ˆNone=è‡ªåŠ¨æ£€æµ‹ï¼‰
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆNone=è‡ªåŠ¨ç”Ÿæˆï¼‰
            prompt: æ­£å‘æç¤ºè¯
            negative_prompt: è´Ÿå‘æç¤ºè¯
            num_inference_steps: æ¨ç†æ­¥æ•°ï¼ˆè¶Šå¤§è¶Šæ…¢ä½†æ•ˆæœè¶Šå¥½ï¼Œæ¨è 30-50ï¼‰
            guidance_scale: å¼•å¯¼å¼ºåº¦ï¼ˆæ¨è 7-8ï¼‰
        """
        # è¯»å–å›¾ç‰‡
        image = Image.open(image_path).convert("RGB")
        original_size = image.size
        
        # è‡ªåŠ¨æ£€æµ‹æ°´å°
        if mask is None:
            mask = self.detect_watermark_auto(image_path)
        
        # è½¬æ¢ mask ä¸º PIL Image
        if isinstance(mask, np.ndarray):
            mask_pil = Image.fromarray(mask).convert("L")
        else:
            mask_pil = mask
        
        # ç¡®ä¿å°ºå¯¸ä¸€è‡´
        mask_pil = mask_pil.resize(original_size, Image.LANCZOS)
        
        # è°ƒæ•´å›¾ç‰‡å¤§å°ï¼ˆSD å¯¹å°ºå¯¸æœ‰è¦æ±‚ï¼Œå¿…é¡»æ˜¯ 8 çš„å€æ•°ï¼‰
        def resize_to_multiple_of_8(img):
            w, h = img.size
            new_w = (w // 8) * 8
            new_h = (h // 8) * 8
            return img.resize((new_w, new_h), Image.LANCZOS)
        
        image_resized = resize_to_multiple_of_8(image)
        mask_resized = resize_to_multiple_of_8(mask_pil)
        
        print(f"\nğŸ¨ å¼€å§‹ AI ä¿®å¤...")
        print(f"   åŸå§‹å°ºå¯¸: {original_size}")
        print(f"   å¤„ç†å°ºå¯¸: {image_resized.size}")
        print(f"   æ¨ç†æ­¥æ•°: {num_inference_steps}")
        print(f"   æç¤ºè¯: {prompt}")
        
        # SD Inpainting
        result = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=image_resized,
            mask_image=mask_resized,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            strength=1.0,  # å®Œå…¨é‡ç»˜ mask åŒºåŸŸ
        ).images[0]
        
        # æ¢å¤åŸå§‹å°ºå¯¸
        if result.size != original_size:
            result = result.resize(original_size, Image.LANCZOS)
        
        # ä¿å­˜ç»“æœ
        if output_path is None:
            base, ext = os.path.splitext(image_path)
            output_path = f"{base}_sd_cleaned{ext}"
        
        result.save(output_path, quality=95)
        print(f"âœ“ ä¿®å¤å®Œæˆï¼ä¿å­˜åˆ°: {output_path}\n")
        
        return result, output_path
    
    def batch_process(self, image_dir, output_dir=None, **kwargs):
        """æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
        image_dir = Path(image_dir)
        
        if output_dir is None:
            output_dir = image_dir / "sd_cleaned"
        else:
            output_dir = Path(output_dir)
        
        output_dir.mkdir(exist_ok=True)
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']
        image_files = [f for f in image_dir.iterdir() 
                      if f.is_file() and f.suffix in extensions]
        
        print(f"\nğŸ“ æ‰¹é‡å¤„ç†æ¨¡å¼")
        print(f"   è¾“å…¥ç›®å½•: {image_dir}")
        print(f"   è¾“å‡ºç›®å½•: {output_dir}")
        print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡\n")
        print("=" * 70)
        
        results = []
        for i, image_file in enumerate(image_files, 1):
            print(f"\n[{i}/{len(image_files)}] å¤„ç†: {image_file.name}")
            print("-" * 70)
            
            try:
                output_path = output_dir / image_file.name
                _, output = self.remove_watermark(
                    str(image_file),
                    output_path=str(output_path),
                    **kwargs
                )
                results.append((str(image_file), output, "æˆåŠŸ"))
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {e}")
                results.append((str(image_file), None, f"å¤±è´¥: {e}"))
        
        print("\n" + "=" * 70)
        print("æ‰¹é‡å¤„ç†å®Œæˆï¼\n")
        
        # ç»Ÿè®¡
        success = sum(1 for _, _, status in results if status == "æˆåŠŸ")
        print(f"âœ“ æˆåŠŸ: {success}/{len(results)}")
        print(f"âœ— å¤±è´¥: {len(results) - success}/{len(results)}")
        
        return results


def main():
    """ä¸»ç¨‹åº - äº¤äº’å¼ç•Œé¢"""
    print("=" * 70)
    print("ğŸ¨ Stable Diffusion æ°´å°å»é™¤å·¥å…·")
    print("   æœ€å¼ºå¤§çš„ AI å›¾åƒä¿®å¤æ–¹æ¡ˆ")
    print("=" * 70)
    print()
    
    # åˆå§‹åŒ–æ¨¡å‹
    try:
        remover = SDWatermarkRemover()
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("\nè¯·ç¡®ä¿å·²å®‰è£…ä¾èµ–:")
        print("   uv pip install diffusers transformers torch pillow opencv-python")
        return
    
    print("\né€‰æ‹©æ¨¡å¼:")
    print("  1. å•å¼ å›¾ç‰‡å¤„ç†")
    print("  2. æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹")
    print()
    
    choice = input("è¯·é€‰æ‹© (1-2): ").strip()
    
    if choice == "1":
        # å•å¼ å›¾ç‰‡
        image_path = input("\nè¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip().strip('"').strip("'")
        if not os.path.exists(image_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return
        
        # è¯¢é—®å‚æ•°
        print("\né«˜çº§é€‰é¡¹ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ï¼‰:")
        steps = input("  æ¨ç†æ­¥æ•° [30-50ï¼Œé»˜è®¤ 40]: ").strip()
        steps = int(steps) if steps else 40
        
        guidance = input("  å¼•å¯¼å¼ºåº¦ [5-10ï¼Œé»˜è®¤ 7.5]: ").strip()
        guidance = float(guidance) if guidance else 7.5
        
        # å¤„ç†
        print()
        remover.remove_watermark(
            image_path,
            num_inference_steps=steps,
            guidance_scale=guidance
        )
        
    elif choice == "2":
        # æ‰¹é‡å¤„ç†
        image_dir = input("\nè¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„: ").strip().strip('"').strip("'")
        if not os.path.exists(image_dir):
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {image_dir}")
            return
        
        # è¯¢é—®å‚æ•°
        print("\né«˜çº§é€‰é¡¹ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤å€¼ï¼‰:")
        steps = input("  æ¨ç†æ­¥æ•° [30-50ï¼Œé»˜è®¤ 40]: ").strip()
        steps = int(steps) if steps else 40
        
        remover.batch_process(
            image_dir,
            num_inference_steps=steps
        )
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return
    
    print("\n" + "=" * 70)
    print("âœ“ å…¨éƒ¨å®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    # å¿«é€Ÿæµ‹è¯•ç”¨æ³•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    test_image = os.path.join(script_dir, "images/11-22/02.JPG")
    
    if len(os.sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        image_path = os.sys.argv[1]
        remover = SDWatermarkRemover()
        remover.remove_watermark(image_path)
    elif os.path.exists(test_image):
        # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
        print("ğŸ§ª æ£€æµ‹åˆ°æµ‹è¯•å›¾ç‰‡ï¼Œç›´æ¥å¤„ç†...")
        remover = SDWatermarkRemover()
        remover.remove_watermark(test_image, num_inference_steps=30)
    else:
        # äº¤äº’æ¨¡å¼
        main()

